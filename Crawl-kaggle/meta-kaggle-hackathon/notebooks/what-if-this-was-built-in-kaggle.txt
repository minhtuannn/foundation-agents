â€œOne day you'll look back and see how well you did.â€
Artwork & Quote by Charlie Mackesy
Some of us have been here for 5 years,
some for 5 months,
and some for 5 days.
And if youâ€™ve ever sat back and thought :
"Am I even getting anywhere with this Kaggle thing?"
trust me, youâ€™re not alone.
We tend to measure progress in medals, prize money, and upvotes
but we often forget our progress ain't just confined to them and those arenâ€™t the only milestones that matter.
Real growth shows in how your notebooks have improved,
how much quicker you debug,
and how confidently can we explain what we've learned.
This notebook isnâ€™t just about data
rather itâ€™s here to reflect how far you have come.
Letâ€™s take a look at your journey so far. ğŸ‘£
ğŸš€ What if This Was Built in Kaggle?
Welcome to your Kaggle Profile Analyzer, a personalized storytelling dashboard powered by Meta Kaggle. Whether youâ€™re here to relive your journey or uncover whatâ€™s next, this maps your Kaggle legacy like never before.
ğŸ“Š Kaggle Profile Analyzer â€“ Feature Summary
Feature What It Shows Visualization Insight Delivered
ğŸ… Medal Journey Timeline Cumulative medals over time (Bronze/Silver/Gold) Line chart (Plotly) Tracks long-term progress and milestone wins
ğŸ“† Weekly Submission Activity Competition submissions per week Time series plot Visualizes consistency and competition hustle
ğŸ·ï¸ Winning Tags Breakdown Top tags/themes where youâ€™ve earned medals Bar chart Highlights your strongest competition domains
ğŸ© Top Winning Tags Top 15 medal-winning tags Donut (Pie) chart Reveals niche areas where you shine
ğŸ§  Domain Clustering & Medal Breakdown Clustered competition domains + medal spread Bar, Sunburst, UMAP Maps domain expertise and medal focus
ğŸ“ Notebook Language Usage Languages used in your notebooks Pie chart Insights into your coding preferences
ğŸ“ˆ Code Length Trends Notebook length over time Line chart Tracks evolution in code-writing effort
ğŸ“¦ Boxplot by Medal Notebook length grouped by medal type Box plot Compares effort vs reward (Gold vs Bronze)
ğŸ”¥ Monthly Notebook Activity Monthly publishing frequency Calendar heatmap Captures your publishing rhythm
â˜ï¸ Notebook Title Word Cloud Frequent words in your notebook titles Word cloud Unveils your recurring themes and topics
ğŸ’¬ Forum Activity Timeline Posting frequency across time Line chart Engagement & presence in community forums
â“ Forum QnA Ratio Ratio of questions vs answers Pie chart Reveals mentor vs learner roles
ğŸŒŸ Forum Word Cloud Most upvoted forum messages Word cloud Highlights highest-impact conversations
ğŸ“¦ Dataset Medals Gold/Silver/Bronze earned from datasets Bar chart Recognizes data contribution excellence
ğŸ“… Dataset Creation Timeline Publishing timeline for datasets Line chart Shows rhythm and momentum in data sharing
ğŸ“Š Dataset Votes & Downloads Engagement stats per dataset Box plots Reflects impact and community reach
ğŸ§  Skill Tag Evolution Timeline Growth of top skill tags across all mediums Multi-line plot Tracks evolving areas of expertise
ğŸ‘¥ Feature Team Graph Graph of co-authors & teammates Network graph Visualizes collaboration history
ğŸ¯ Top Competition Recommendations Personalized future competitions Text / Cards Surfaces smart paths forward based on past
ğŸš€ Ready to Explore Your Kaggle Journey?
Well guess what... You're not just reading about these features â€” you are about to interact with them! Iâ€™ve tried to wrap it all into an experience using Gradio. Youâ€™ll be able to:
ğŸ“ˆ Explore your medal milestones
ğŸ’¡ Dive into your competition domains
ğŸ“š See your notebook patterns & progress
â˜ï¸ Discover your most-used themes
ğŸ“† Visualize your consistency in heatmaps
ğŸ§  Uncover your language preferences
...and so much more!
ğŸ¯ How It Works:
Run every single cell ( one at a tine), enter your Kaggle username, and let the notebook handle the rest. Itâ€™ll fetch your public data from Meta Kaggle and turn it into beautiful visual stories using Plotly, WordCloud, and UMAP!
âš¡ This isnâ€™t just a dashboard â€” itâ€™s a mirror of your growth as a Kaggle Data Scientist. Because, trust me your journey is beyond the number of medals and prize money you earned.
ğŸ’» Letâ€™s Begin!
ğŸ‘‡ Scroll below to run each feature or explore them one by one. Your journey awaits.
ğŸ“¦ Installing Gradio â€” Our Interactive Frontend Engine
Before diving into the depths of Kaggle user behavior and intelligent visualizations, let's equip ourselves with Gradio â€” the powerhouse library that transforms our data science analyses into elegant, shareable web apps.
This notebook isnâ€™t just about static charts â€” itâ€™s about bringing Kaggle personas to life. With a single command, we unlock interactive magic. âœ¨
In [1]:
!pip install gradio > /dev/null 2>&1
ğŸ§° Importing Libraries
To unlock insights from the Meta Kaggle dataset, we bring together a curated set of powerful libraries â€” each with a unique role in this exploration: ğŸ“¦ kagglehub â€“ Interface to interact with Meta Kaggle assets directly. ğŸ“Š pandas â€“ For data manipulation and wrangling. ğŸ“ os â€“ For navigating file paths and system operations. ğŸ“ˆ plotly â€“ Interactive plots for timelines, trends, and heatmaps. ğŸ¨ matplotlib / WordCloud â€“ For creating aesthetic word clouds and static visuals. ğŸ§  sentence-transformers â€“ To embed text (like competition titles or tags) into numerical vectors for clustering and similarity. ğŸ§ª scikit-learn â€“ For clustering (KMeans) and text vectorization (TfidfVectorizer + cosine_similarity). ğŸŒ networkx â€“ To visualize collaboration networks among Kagglers. ğŸ›ï¸ gradio â€“ To wrap all insights into a clean, interactive web interface.
In [2]:
import kagglehub
import pandas as pd
import os
import plotly.graph_objects as go
import gradio as gr
import plotly.express as px
import numpy
from sentence_transformers import SentenceTransformer
from sklearn.cluster import KMeans
import plotly.express as px
from wordcloud import WordCloud
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import networkx as nx
import plotly.io as pio
pio.renderers.default = 'iframe_connected'
2025-07-27 14:56:43.014973: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered
WARNING: All log messages before absl::InitializeLog() is called are written to STDERR
E0000 00:00:1753628203.230047      35 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered
E0000 00:00:1753628203.300842      35 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered
ğŸ“¥ Fetching the two Primary Datasets
In [3]:
MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")
MKC_PATH = kagglehub.dataset_download("kaggle/meta-kaggle-code")

print("Path to Meta-Kaggle dataset files:", MK_PATH)
print("Path to Meta-Kaggle-Code dataset files:", MKC_PATH)
Path to Meta-Kaggle dataset files: /kaggle/input/meta-kaggle
Path to Meta-Kaggle-Code dataset files: /kaggle/input/meta-kaggle-code
The Meta Kaggle Dataset
Before diving into analysis, let's list down rich tapestry of the Meta Kaggle dataset â€” Kaggleâ€™s internal mirror of its entire platform activity. From competitions to kernels, forums to datasets, the ecosystem is vast and deeply interconnected. To understand the full scope, we listed some of the CSV files used in this analysis, including: ğŸ† Competitions.csv ğŸ§  KernelVersions.csv, KernelVotes.csv, KernelTags.csv ğŸ“Š Datasets.csv, DatasetVersions.csv, DatasetVotes.csv ğŸ§µ ForumMessages.csv, ForumTopics.csv, ForumMessageReactions.csv ğŸ§¬ Models.csv, ModelVersions.csv, ModelTags.csv ğŸ‘¥ Users.csv, Teams.csv, TeamMemberships.csv ğŸ·ï¸ Tags.csv, CompetitionTags.csv, DatasetTags.csv For each file, we extracted only the column headers, giving us a high-level view of the structure of the data.
ğŸŒŸ It Has Begun...
You've set the stage, installed the libraries. Now, it's time to witness your Kaggle story â€” one feature at a time.
Weâ€™ll start with a journey with a hope that every Kaggler would hold it dearly. From the adrenaline of that first Bronze to the sweet triumph of Gold, your timeline is more than just a chart â€” itâ€™s a reflection of grit, growth, and grind.
ğŸ§­ Ready to turn data into dÃ©jÃ  vu?
Letâ€™s begin where every legend does â€” at their first victory.
ğŸ… Your Medal Journey Timeline
Every Kaggle user remembers the moment they won their first medal â€” that tiny notification that made the struggle worth it.
But what if you could zoom out and see the whole story? From your very first Bronze to your latest Gold, this feature maps your cumulative medal timeline across every competition.
Whether you're chasing your first medal or your fiftieth, this graph lets you pause, reflect, and feel proud of how far youâ€™ve come.
âœ¨ What you'll see:
Interactive timeline of Bronze, Silver, and Gold medals earned
Cumulative medal count showing your progression over the months
A bold Total trend line to visualize your full journey at a glance
ğŸ“Š Built with plotly Â· ğŸ§  Powered by Meta Kaggle Â· âš¡ï¸ Interactive via Gradio
ğŸš€ Ready to relive your journey?
Just type in your Kaggle username and hit Submit. Weâ€™ll take care of the rest.
In [4]:
import pandas as pd
import plotly.graph_objects as go
import gradio as gr

# Constants
MK_PATH = "/kaggle/input/meta-kaggle"
MEDAL_COLORS = {
    "Gold": "#FFD700",
    "Silver": "#C0C0C0",
    "Bronze": "#CD7F32",
    "Total": "#FFFFFF"
}
MEDAL_MAP = {1: "Gold", 2: "Silver", 3: "Bronze"}

# Utils
def get_user_id(username):
    users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
    return users.loc[users["UserName"] == username, "Id"].values[0]

def get_user_teams(user_id):
    memberships = pd.read_csv(f"{MK_PATH}/TeamMemberships.csv", usecols=["TeamId", "UserId"])
    return memberships[memberships["UserId"] == user_id]["TeamId"].unique()

def get_medal_timeline(team_ids):
    teams = pd.read_csv(
        f"{MK_PATH}/Teams.csv", 
        usecols=["Id", "Medal", "MedalAwardDate"],
        dtype={"Medal": "str"}, 
        low_memory=False
    )
    teams = teams[teams["Id"].isin(team_ids)]
    teams["MedalAwardDate"] = pd.to_datetime(teams["MedalAwardDate"], errors="coerce")
    teams["Medal"] = pd.to_numeric(teams["Medal"], errors="coerce").map(MEDAL_MAP)
    teams = teams.dropna(subset=["MedalAwardDate", "Medal"])

    timeline = teams.groupby(["MedalAwardDate", "Medal"]).size().unstack(fill_value=0).sort_index()
    timeline = timeline.cumsum()
    timeline["Total"] = timeline.sum(axis=1)
    return timeline.reset_index()

def plot_medal_progress(timeline, username):
    fig = go.Figure()
    for medal in ["Bronze", "Silver", "Gold"]:
        if medal in timeline.columns:
            fig.add_trace(go.Scatter(
                x=timeline["MedalAwardDate"],
                y=timeline[medal],
                mode="lines+markers",
                name=medal,
                line=dict(color=MEDAL_COLORS[medal], width=2),
                marker=dict(size=6),
                hovertemplate=f"%{{x|%b %d, %Y}}<br>{medal}: %{{y}}<extra></extra>"
            ))

    fig.add_trace(go.Scatter(
        x=timeline["MedalAwardDate"],
        y=timeline["Total"],
        mode="lines+markers",
        name="â­ Total",
        line=dict(color=MEDAL_COLORS["Total"], width=3, dash="dash"),
        marker=dict(size=6),
        hovertemplate="%{x|%b %d, %Y}<br>Total: %{y}<extra></extra>"
    ))

    fig.update_layout(
        title=dict(text=f"\U0001F3C6 @{username} - Medal Progress", x=0.5, font=dict(size=20)),
        xaxis_title="Date",
        yaxis_title="Cumulative Medals",
        template="plotly_dark",
        plot_bgcolor="#111111",
        paper_bgcolor="#111111",
        font=dict(color="white"),
        legend=dict(
            title="Medal Type",
            bgcolor="#1a1a1a",
            bordercolor="#333",
            borderwidth=1
        ),
        hovermode="x unified",
        height=550,
        margin=dict(t=80, b=60, l=60, r=40)
    )
    return fig

# Gradio function
def analyze_medals(username):
    try:
        user_id = get_user_id(username)
        team_ids = get_user_teams(user_id)
        timeline = get_medal_timeline(team_ids)
        return plot_medal_progress(timeline, username)
    except Exception as e:
        return f"Error: {str(e)}"

# Updated Description Block
description_html = """
<div style="background-color:#1c1c1c; padding: 25px; border-radius: 12px; border: 1px solid #333; margin-bottom: 30px">

<h2 style="color: #FFD700; margin-bottom: 12px;">ğŸ… Your Medal Journey Timeline</h2>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
Every Kaggle user remembers the moment they won their first medal â€” that tiny notification that made the struggle worth it.
</p>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
But what if you could <strong style="color: #87CEFA;">zoom out</strong> and see the whole story?  
From your very first <span style="color:#CD7F32;">Bronze</span> to your latest <span style="color:#FFD700;">Gold</span>, this feature maps your <strong style="color: #FFFFFF;">cumulative medal timeline</strong> across every competition.
</p>

<p style="color: #aaa; font-size: 15px; margin-top: 12px;">
Whether you're chasing your <em>first</em> medal or your <em>fiftieth</em>, this graph lets you pause, reflect, and feel proud of how far youâ€™ve come.
</p>

<hr style="border: none; height: 1px; background: #333; margin: 25px 0;" />

<h3 style="color: #f2f2f2; margin-bottom: 10px;">âœ¨ What you'll see:</h3>
<ul style="color: #ccc; font-size: 15px; line-height: 1.6;">
  <li><strong>Interactive timeline</strong> of Bronze, Silver, and Gold medals earned</li>
  <li><strong>Cumulative medal count</strong> showing your progression over the months</li>
  <li>A bold <strong>Total trend line</strong> to visualize your full journey at a glance</li>
</ul>

<p style="color: #999; font-size: 14px; margin-top: 25px;">
ğŸ“Š Built with <code>plotly</code> Â· ğŸ§  Powered by <a href="https://www.kaggle.com/datasets/kaggle/meta-kaggle" target="_blank" style="color:#00BFFF;">Meta Kaggle</a> Â· âš¡ï¸ Interactive via <code>Gradio</code>
</p>

<hr style="border: none; height: 1px; background: #333; margin: 25px 0;" />

<h4 style="color: #90ee90; margin-bottom: 5px;">ğŸš€ Ready to relive your journey?</h4>
<p style="color: #bbb; font-size: 15px;">
Just type in your Kaggle username and hit <strong>Submit</strong>. Weâ€™ll take care of the rest.
</p>

</div>
"""

# Gradio Interface
demo = gr.Interface(
    fn=analyze_medals,
    inputs=gr.Textbox(label="Enter Kaggle Username"),
    outputs=gr.Plot(label="Medal Timeline"),
    title="\U0001F3C5 Kaggle Medal Progress Tracker",
    description=description_html,
    theme="dark"
)

demo.launch(share=True)
/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1195: UserWarning:

Cannot load dark. Caught Exception: 404 Client Error: Not Found for url: https://huggingface.co/api/spaces/dark (Request ID: Root=1-68863e3d-24a856da1527b5660656ffc1;3304455c-d5f3-4248-86b3-9a1a1821ea5f)

Sorry, we can't find the page you are looking for.
* Running on local URL:  http://127.0.0.1:7860
* Running on public URL: https://d4fb91caff2fa869b4.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[4]:
ğŸ“† Weekly Submission Activity
Winning a competition is great â€” but the real power lies in showing up week after week. This chart captures your submission consistency over time.
Whether you submitted once or twenty times in a week, this timeline visualizes your grit and persistence. Because progress isn't just measured in medals â€” it's measured in momentum.
ğŸ“Š What you'll see:
Weekly activity trend of how often you submitted to competitions
A clear visual of consistency bursts and off-weeks
Zoomable, interactive timeline for deeper insights
ğŸ“¤ Built with plotly Â· ğŸ” Data from Meta Kaggle Â· âš¡ï¸ Try it live via Gradio below
ğŸ¯ Ready to track your hustle?
Enter your Kaggle username below and hit Submit. Letâ€™s see how consistently youâ€™ve been showing up.
In [5]:
import pandas as pd
import plotly.graph_objects as go
import gradio as gr
import kagglehub  # If using locally / Kaggle Kernels

def submission_activity(username):
    try:
        # ğŸ”¹ SETUP
        MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")

        # STEP 1: Get UserId
        users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
        user_id = users.loc[users["UserName"] == username, "Id"].values[0]

        # STEP 2: Get all TeamIds for this user
        memberships = pd.read_csv(f"{MK_PATH}/TeamMemberships.csv", usecols=["TeamId", "UserId"])
        user_teams = memberships[memberships["UserId"] == user_id]["TeamId"].unique()

        # STEP 3: Submissions for these teams
        subs = pd.read_csv(f"{MK_PATH}/Submissions.csv", usecols=["TeamId", "SubmissionDate"])
        subs = subs[subs["TeamId"].isin(user_teams)]
        subs["SubmissionDate"] = pd.to_datetime(subs["SubmissionDate"], errors="coerce")
        subs = subs.dropna(subset=["SubmissionDate"])

        # STEP 4: Weekly submission pattern
        weekly_subs = subs.groupby(pd.Grouper(key="SubmissionDate", freq="W"))["TeamId"].count().reset_index()
        weekly_subs.rename(columns={"TeamId": "SubmissionCount"}, inplace=True)

        # STEP 5: Plot
        fig = go.Figure()
        fig.add_trace(go.Scatter(
            x=weekly_subs["SubmissionDate"],
            y=weekly_subs["SubmissionCount"],
            mode="lines+markers",
            name="ğŸ“¤ Submissions",
            line=dict(color="#1f77b4", width=2),
            marker=dict(size=6),
            hovertemplate="%{x|%b %d, %Y}<br>Submissions: %{y}<extra></extra>"
        ))

        # STEP 6: Styling
        fig.update_layout(
            title=dict(text=f"{username}'s Weekly Submission Activity", x=0.5, font=dict(size=20)),
            xaxis_title="Week",
            yaxis_title="Submissions Made",
            template="plotly_dark",
            plot_bgcolor="#1a1a1a",
            paper_bgcolor="#1a1a1a",
            font=dict(color="white"),
            hovermode="x unified",
            height=500
        )
        return fig
    except Exception as e:
        return f"âš ï¸ Error: Could not find data for '{username}'. Please check the username."

# Styled Description
description_html = """
<div style="background-color:#1c1c1c; padding: 25px; border-radius: 12px; border: 1px solid #333; margin-bottom: 30px">

<h2 style="color: #00BFFF; margin-bottom: 12px;">ğŸ“† Weekly Submission Activity</h2>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
Winning a competition is great â€” but the real power lies in showing up <em>week after week</em>. This chart captures your <strong style="color: #87CEFA;">submission consistency</strong> over time.
</p>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
Whether you submitted once or twenty times in a week, this timeline visualizes your <strong>grit and persistence</strong>. Because progress isn't just measured in medals â€” it's measured in momentum.
</p>

<hr style="border: none; height: 1px; background: #333; margin: 25px 0;" />

<h3 style="color: #f2f2f2; margin-bottom: 10px;">ğŸ“Š What you'll see:</h3>
<ul style="color: #ccc; font-size: 15px; line-height: 1.6;">
  <li><strong>Weekly activity trend</strong> of how often you submitted to competitions</li>
  <li>A clear visual of <strong>consistency bursts</strong> and off-weeks</li>
  <li><strong>Zoomable, interactive timeline</strong> for deeper insights</li>
</ul>

<p style="color: #999; font-size: 14px; margin-top: 25px;">
ğŸ“¤ Built with <code>plotly</code> Â· ğŸ” Data from <a href="https://www.kaggle.com/datasets/kaggle/meta-kaggle" target="_blank" style="color:#00BFFF;">Meta Kaggle</a> Â· âš¡ï¸ Try it live via <code>Gradio</code> below
</p>

<hr style="border: none; height: 1px; background: #333; margin: 25px 0;" />

<h4 style="color: #90ee90; margin-bottom: 5px;">ğŸ¯ Ready to track your hustle?</h4>
<p style="color: #bbb; font-size: 15px;">
Enter your Kaggle username below and hit Submit. Letâ€™s see how consistently youâ€™ve been showing up.
</p>

</div>
"""

# Gradio Interface with Markdown
gr.Interface(
    fn=submission_activity,
    inputs=gr.Textbox(label="Enter Kaggle Username", placeholder="e.g. christofhenkel"),
    outputs=gr.Plot(label="Weekly Submission Activity Timeline"),
    title="ğŸ“† Kaggle Weekly Submission Tracker",
    description=description_html,
    theme="dark"
).launch()
/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1195: UserWarning:

Cannot load dark. Caught Exception: 404 Client Error: Not Found for url: https://huggingface.co/api/spaces/dark (Request ID: Root=1-68863e3f-2f68ea320c2112011886396a;81d7a504-b914-4851-9d1c-063b762e4968)

Sorry, we can't find the page you are looking for.
* Running on local URL:  http://127.0.0.1:7861
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://5b079faf740d6aa11a.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[5]:
ğŸ… Winning Tags Breakdown
Behind every gold medal lies a story â€” not just of effort, but of expertise in a theme. This chart reveals which competition tags youâ€™ve repeatedly won in. Think of it as your Kaggle niche radar.
It answers questions like:
ğŸ” What domains are you most successful in?
ğŸ·ï¸ Are you a tabular wizard or NLP whisperer?
ğŸ“Š Which tags dominate your medal cabinet?
ğŸ“ˆ Winning teams only Â· Tags extracted from medal-winning competitions Â· Visualized with plotly bar chart
ğŸ¯ Want to discover your own winning themes?
Type your Kaggle username below and let the magic unfold.
In [6]:
def winning_tags(username):
    try:
        # Setup
        MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")

        # Step 1: Get UserId
        users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
        user_id = users.loc[users["UserName"] == username, "Id"].values[0]

        # Step 2: All teams the user was part of
        memberships = pd.read_csv(f"{MK_PATH}/TeamMemberships.csv", usecols=["TeamId", "UserId"])
        user_teams = memberships[memberships["UserId"] == user_id]["TeamId"].unique()

        # Step 3: Filter medal-winning teams
        teams = pd.read_csv(f"{MK_PATH}/Teams.csv", usecols=["Id", "Medal", "CompetitionId"])
        winning_teams = teams[teams["Id"].isin(user_teams) & teams["Medal"].isin([1, 2, 3])]

        if winning_teams.empty:
            return "ğŸ¥² No medal-winning competitions found for this user."

        # Step 4: Get relevant competition IDs
        winning_comps = winning_teams["CompetitionId"].unique()

        # Step 5: Get tag IDs for those competitions
        comp_tags = pd.read_csv(f"{MK_PATH}/CompetitionTags.csv", usecols=["CompetitionId", "TagId"])
        relevant_tags = comp_tags[comp_tags["CompetitionId"].isin(winning_comps)]["TagId"]

        # Step 6: Map TagId to Tag Names
        tags = pd.read_csv(f"{MK_PATH}/Tags.csv", usecols=["Id", "Name"])
        tag_names = tags[tags["Id"].isin(relevant_tags)]

        # Step 7: Count frequency
        tag_counts = tag_names["Name"].value_counts().reset_index()
        tag_counts.columns = ["Tag", "Count"]

        # Step 8: Plot
        fig = px.bar(
            tag_counts.sort_values("Count", ascending=True),
            x="Count",
            y="Tag",
            orientation="h",
            title=f"{username}'s Winning Competition Tags",
            template="plotly_dark",
            color="Count",
            color_continuous_scale="viridis"
        )
        fig.update_layout(
            plot_bgcolor="#1a1a1a",
            paper_bgcolor="#1a1a1a",
            font=dict(color="white"),
            height=600
        )
        return fig
    except Exception as e:
        return f"âš ï¸ Error: Could not fetch tags for '{username}'. Please check the username."

# Styled Description HTML
desc = """
<div style="background-color:#1c1c1c; padding: 25px; border-radius: 12px; border: 1px solid #333; margin-bottom: 30px">

<h2 style="color: #FFD700; margin-bottom: 12px;">ğŸ… Winning Tags Breakdown</h2>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
Behind every gold medal lies a story â€” not just of effort, but of <strong style="color:#FFD700;">expertise in a theme</strong>. This chart reveals which competition tags youâ€™ve repeatedly won in. Think of it as your <em>Kaggle niche radar</em>.
</p>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
It answers questions like:
<ul style="color: #ccc; font-size: 15px; line-height: 1.6;">
  <li>ğŸ” What domains are you most successful in?</li>
  <li>ğŸ·ï¸ Are you a tabular wizard or NLP whisperer?</li>
  <li>ğŸ“Š Which tags dominate your medal cabinet?</li>
</ul>
</p>

<hr style="border: none; height: 1px; background: #333; margin: 25px 0;" />

<p style="color: #999; font-size: 14px;">
ğŸ“ˆ Winning teams only Â· Tags extracted from medal-winning competitions Â· Visualized with <code>plotly</code> bar chart
</p>

<h4 style="color: #90ee90; margin-top: 25px;">ğŸ¯ Want to discover your own winning themes?</h4>
<p style="color: #bbb; font-size: 15px;">
Type your Kaggle username below and let the magic unfold.
</p>

</div>
"""

# Gradio Interface with Styled Description
gr.Interface(
    fn=winning_tags,
    inputs=gr.Textbox(label="Enter Kaggle Username", placeholder="e.g. christofhenkel"),
    outputs=gr.Plot(label="Winning Tags Breakdown"),
    title="ğŸ·ï¸ Your Winning Domains on Kaggle",
    description=desc,
    theme="dark"
).launch()
/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1195: UserWarning:

Cannot load dark. Caught Exception: 404 Client Error: Not Found for url: https://huggingface.co/api/spaces/dark (Request ID: Root=1-68863e42-506199c72fbd8b24774a6a58;99f8d3fc-ea38-48da-9477-e578dd3f522e)

Sorry, we can't find the page you are looking for.
* Running on local URL:  http://127.0.0.1:7862
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://00d727e93866873543.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[6]:
ğŸ© Your Top Winning Tags
Medals donâ€™t just reward your effort â€” they reveal your pattern. This donut chart showcases the top tags across all your medal-winning competitions, giving you a curated glimpse into where youâ€™ve consistently excelled.
Whether itâ€™s time-series forecasting, satellite imaging, or sports analytics, these are the themes where you didnâ€™t just compete â€” you conquered.
ğŸ“Š Top 15 tags extracted from your medal-winning competitions Â· Pie-style chart with plotly.graph_objects
ğŸ¯ Curious about what your winning edge looks like?
Just enter your Kaggle handle and watch your strengths surface â€” in 360Â°.
In [7]:
import pandas as pd
import plotly.graph_objects as go
import plotly.express as px
import kagglehub
import gradio as gr
from IPython.display import display, HTML

def load_winning_tags(username):
    # ğŸ”¹ Step 0: Setup
    MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")
    
    # Step 1: Get UserId
    users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
    if username not in users["UserName"].values:
        return go.Figure().update_layout(title="User not found.")
    
    user_id = users.loc[users["UserName"] == username, "Id"].values[0]
    
    # Step 2: All teams the user was part of
    memberships = pd.read_csv(f"{MK_PATH}/TeamMemberships.csv", usecols=["TeamId", "UserId"])
    user_teams = memberships[memberships["UserId"] == user_id]["TeamId"].unique()
    
    # Step 3: Filter medal-winning teams
    teams = pd.read_csv(f"{MK_PATH}/Teams.csv", usecols=["Id", "Medal"])
    teams = teams[teams["Id"].isin(user_teams) & teams["Medal"].isin([1, 2, 3])]
    if teams.empty:
        return go.Figure().update_layout(title="No medals found for this user.")
    
    winning_team_ids = teams["Id"].unique()
    
    # Step 4: Get competition IDs for those teams
    teams_with_comp = pd.read_csv(f"{MK_PATH}/Teams.csv", usecols=["Id", "CompetitionId"])
    winning_comps = teams_with_comp[teams_with_comp["Id"].isin(winning_team_ids)]["CompetitionId"].unique()
    
    # Step 5: Get tag IDs from those competitions
    comp_tags = pd.read_csv(f"{MK_PATH}/CompetitionTags.csv", usecols=["CompetitionId", "TagId"])
    relevant_tags = comp_tags[comp_tags["CompetitionId"].isin(winning_comps)]["TagId"]
    
    # Step 6: Map TagId to Tag Names
    tags = pd.read_csv(f"{MK_PATH}/Tags.csv", usecols=["Id", "Name"])
    tag_names = tags[tags["Id"].isin(relevant_tags)]
    
    # Step 7: Count frequency of each tag
    tag_counts = tag_names["Name"].value_counts().reset_index()
    tag_counts.columns = ["Tag", "Count"]
    
    # Optional: Limit to Top 15
    top_tags = tag_counts.head(15)
    
    # Step 8: Donut Chart
    fig = go.Figure(data=[go.Pie(
        labels=top_tags["Tag"],
        values=top_tags["Count"],
        hole=0.45,
        marker=dict(colors=px.colors.sequential.Viridis),
        textinfo='label+percent',
        hoverinfo='label+value'
    )])
    
    fig.update_layout(
        title=f"{username}'s Top Tags from Winning Competitions",
        template="plotly_dark",
        plot_bgcolor="#1a1a1a",
        paper_bgcolor="#1a1a1a",
        font=dict(color="white"),
        height=550
    )
    
    return fig

# âœ… Styled Markdown Display
display(HTML("""
<div style="background-color:#1c1c1c; padding: 25px; border-radius: 12px; border: 1px solid #333; margin-bottom: 30px">

<h2 style="color: #FFD700; margin-bottom: 12px;">ğŸ© Your Top Winning Tags</h2>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
Medals donâ€™t just reward your effort â€” they reveal your pattern. This donut chart showcases the <strong style="color:#FFD700;">top tags</strong> across all your medal-winning competitions, giving you a curated glimpse into where youâ€™ve consistently excelled.
</p>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
Whether itâ€™s <em>time-series forecasting</em>, <em>satellite imaging</em>, or <em>sports analytics</em>, these are the themes where you didnâ€™t just compete â€” <strong>you conquered</strong>.
</p>

<hr style="border: none; height: 1px; background: #333; margin: 25px 0;" />

<p style="color: #bbb; font-size: 14px;">
ğŸ“Š Top 15 tags extracted from your medal-winning competitions Â· Pie-style chart with <code>plotly.graph_objects</code>
</p>

<h4 style="color: #90ee90; margin-top: 25px;">ğŸ¯ Curious about what your winning edge looks like?</h4>
<p style="color: #bbb; font-size: 15px;">
Just enter your Kaggle handle and watch your strengths surface â€” in 360Â°.
</p>

</div>
"""))

# âœ… Gradio Interface
demo = gr.Interface(
    fn=load_winning_tags,
    inputs=gr.Textbox(label="Enter Kaggle Username", placeholder="e.g. christofhenkel"),
    outputs=gr.Plot(label="ğŸ… Top Tags from Winning Competitions"),
    title="Top Competition Tags (Medal-Winning Only)",
    theme="soft",
    description="Discover the themes youâ€™ve excelled in. This donut chart highlights your top 15 competition tags from all medal-winning submissions."
)

demo.launch()
ğŸ© Your Top Winning Tags
Medals donâ€™t just reward your effort â€” they reveal your pattern. This donut chart showcases the top tags across all your medal-winning competitions, giving you a curated glimpse into where youâ€™ve consistently excelled.
Whether itâ€™s time-series forecasting, satellite imaging, or sports analytics, these are the themes where you didnâ€™t just compete â€” you conquered.
ğŸ“Š Top 15 tags extracted from your medal-winning competitions Â· Pie-style chart with plotly.graph_objects
ğŸ¯ Curious about what your winning edge looks like?
Just enter your Kaggle handle and watch your strengths surface â€” in 360Â°.
* Running on local URL:  http://127.0.0.1:7863
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://8f740d5bc9e554985f.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[7]:
ğŸŒ Your Competitive Domain Map
Every competition tells a story. And when you look at the themes youâ€™ve competed in, a pattern emerges â€” a map of your growing expertise. This bar chart highlights the domains you've most frequently contributed to, revealing where your skills shine the brightest.
From Computer Vision to Genomics, NLP to Finance, these clusters are derived using sentence embeddings and KMeans, giving a powerful glance into your unique Kaggle fingerprint.
ğŸ§  Domain classification based on competition titles, subtitles, and overviews Â· Embeddings by all-MiniLM-L6-v2 Â· Clustered using KMeans (n=10)
âœ¨ Wondering where you dominate?
Just enter your Kaggle handle and let your expertise speak for itself.
In [8]:
import gradio as gr
import pandas as pd
import plotly.express as px
import numpy as np
from sklearn.cluster import KMeans
from sentence_transformers import SentenceTransformer
import kagglehub

def domain_expertise(username):
    MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")

    # Load and combine competition text
    competitions = pd.read_csv(
        f"{MK_PATH}/Competitions.csv",
        usecols=["Id", "Title", "Subtitle", "Overview"]
    )
    competitions["full_text"] = (
        competitions["Title"].fillna("") + " " +
        competitions["Subtitle"].fillna("") + " " +
        competitions["Overview"].fillna("")
    )

    # Generate embeddings and cluster
    model = SentenceTransformer("all-MiniLM-L6-v2")
    embeddings = model.encode(competitions["full_text"].tolist(), normalize_embeddings=True)
    competitions["embedding"] = embeddings.tolist()

    X = np.vstack(competitions["embedding"].to_numpy())
    kmeans = KMeans(n_clusters=10, random_state=42, n_init='auto')
    competitions["Cluster"] = kmeans.fit_predict(X)

    # Map clusters to domain names
    cluster_to_domain = {
        0: "Computer Vision", 1: "NLP", 2: "Tabular", 3: "Time Series",
        4: "Reinforcement Learning", 5: "Genomics", 6: "Finance",
        7: "Healthcare", 8: "Recommendation Systems", 9: "Other"
    }
    competitions["Domain"] = competitions["Cluster"].map(cluster_to_domain)

    # Get User ID
    users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
    user_id = users.loc[users["UserName"] == username, "Id"].values[0]

    # Get user's teams
    memberships = pd.read_csv(f"{MK_PATH}/TeamMemberships.csv", usecols=["TeamId", "UserId"])
    user_teams = memberships[memberships["UserId"] == user_id]["TeamId"].unique()

    # Get competitions those teams participated in
    teams = pd.read_csv(
        f"{MK_PATH}/Teams.csv", usecols=["Id", "Medal", "CompetitionId"]
    )
    teams = teams[teams["Id"].isin(user_teams)]

    user_competitions = teams.merge(
        competitions[["Id", "Domain"]], left_on="CompetitionId", right_on="Id", how="left"
    )

    # Count domain frequency
    domain_counts = user_competitions["Domain"].value_counts().reset_index()
    domain_counts.columns = ["Domain", "Count"]

    # Bar chart
    fig = px.bar(domain_counts, x="Domain", y="Count", color="Domain", title="ğŸ† Domain Expertise")
    fig.update_layout(template="plotly_dark")

    return fig

# Gradio Interface
gr.Interface(
    fn=domain_expertise,
    inputs=gr.Textbox(label="ğŸ‘¤ Kaggle Username", placeholder="e.g. ambrosm"),
    outputs=gr.Plot(label="ğŸ“Š Domain Breakdown"),
    title="ğŸŒ Kaggle Domain Expertise",
    description="""
<div style="background-color:#1c1c1c; padding: 25px; border-radius: 12px; border: 1px solid #333; margin-bottom: 30px">

<h2 style="color: #90ee90; margin-bottom: 12px;">ğŸŒ Your Competitive Domain Map</h2>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
Every competition tells a story. And when you look at the themes youâ€™ve competed in, a pattern emerges â€” a map of your growing expertise. This bar chart highlights the <strong style="color:#90ee90;">domains you've most frequently contributed to</strong>, revealing where your skills shine the brightest.
</p>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
From <em>Computer Vision</em> to <em>Genomics</em>, <em>NLP</em> to <em>Finance</em>, these clusters are derived using sentence embeddings and KMeans, giving a powerful glance into your unique Kaggle fingerprint.
</p>

<hr style="border: none; height: 1px; background: #333; margin: 25px 0;" />

<p style="color: #bbb; font-size: 14px;">
ğŸ§  Domain classification based on competition titles, subtitles, and overviews Â· Embeddings by <code>all-MiniLM-L6-v2</code> Â· Clustered using <code>KMeans (n=10)</code>
</p>

<h4 style="color: #FFD700; margin-top: 25px;">âœ¨ Wondering where you dominate?</h4>
<p style="color: #bbb; font-size: 15px;">
Just enter your Kaggle handle and let your expertise speak for itself.
</p>

</div>
""",
    theme="dark"
).launch()
/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1195: UserWarning:

Cannot load dark. Caught Exception: 404 Client Error: Not Found for url: https://huggingface.co/api/spaces/dark (Request ID: Root=1-68863e47-3b24df684a9b28c70778d166;a612f00b-c3b4-482e-b5fd-3888eae8d8d8)

Sorry, we can't find the page you are looking for.
* Running on local URL:  http://127.0.0.1:7864
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://90033a18de17c42705.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[8]:
ğŸ¥‡ The Anatomy of Your Medals
Medals are more than metalâ€”theyâ€™re echoes of your grit, grind, and growth. But where exactly are these victories anchored? What domains truly know your name?
This sunburst visualization breaks down your accolades across competition domains â€” revealing whether youâ€™re a visionary in Computer Vision, a tabular titan, or a sequence sorcerer. ğŸŒŒ
Each ring, each branch, tells a story of perseverance, positioning, and purpose. Let's step inside your medal galaxy.
In [9]:
def medal_breakdown_sunburst(username):
    MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")

    users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
    user_id = users.loc[users["UserName"] == username, "Id"].values[0]

    memberships = pd.read_csv(f"{MK_PATH}/TeamMemberships.csv", usecols=["TeamId", "UserId"])
    user_teams = memberships[memberships["UserId"] == user_id]["TeamId"].unique()

    teams = pd.read_csv(f"{MK_PATH}/Teams.csv", usecols=["Id", "Medal", "CompetitionId"], low_memory=False)
    teams = teams[teams["Id"].isin(user_teams)]

    competitions = pd.read_csv(f"{MK_PATH}/Competitions.csv", usecols=["Id", "Title", "Subtitle", "Overview"])
    competitions["full_text"] = competitions["Title"].fillna("") + " " + competitions["Subtitle"].fillna("") + " " + competitions["Overview"].fillna("")

    from sentence_transformers import SentenceTransformer
    from sklearn.cluster import KMeans
    import numpy as np

    model = SentenceTransformer("all-MiniLM-L6-v2")
    embeddings = model.encode(competitions["full_text"].tolist(), batch_size=128, normalize_embeddings=True)
    competitions["embedding"] = embeddings.tolist()

    X = np.vstack(competitions["embedding"].to_numpy())
    kmeans = KMeans(n_clusters=10, random_state=42, n_init='auto')
    competitions["Cluster"] = kmeans.fit_predict(X)
    cluster_to_domain = {
        0: "Computer Vision", 1: "NLP", 2: "Tabular", 3: "Time Series",
        4: "Reinforcement Learning", 5: "Genomics", 6: "Finance",
        7: "Healthcare", 8: "Recommendation Systems", 9: "Other"
    }
    competitions["Domain"] = competitions["Cluster"].map(cluster_to_domain)

    user_competitions = teams.merge(
        competitions[["Id", "Domain"]],
        left_on="CompetitionId", right_on="Id", how="left"
    )
    medal_map = {1: "Gold", 2: "Silver", 3: "Bronze"}
    user_competitions["Medal"] = pd.to_numeric(user_competitions["Medal"], errors="coerce").map(medal_map)

    fig = px.sunburst(
        user_competitions.dropna(subset=["Medal", "Domain"]),
        path=["Domain", "Medal"],
        title="ğŸ¥‡ Expertise Breakdown by Domain & Medal"
    )
    fig.update_layout(template="plotly_dark")
    return fig

gr.Interface(
    fn=medal_breakdown_sunburst,
    inputs=gr.Textbox(label="ğŸ‘¤ Enter Kaggle Username"),
    outputs=gr.Plot(label="ğŸ¥‡ Medal Breakdown Sunburst"),
    title="ğŸ¯ Kaggle Medal Breakdown",
    description="Explore how this Kaggle user's medals are distributed across different competition domains.",
    theme="dark"
).launch()
/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1195: UserWarning:

Cannot load dark. Caught Exception: 404 Client Error: Not Found for url: https://huggingface.co/api/spaces/dark (Request ID: Root=1-68863e49-4af61f2f162d054500303514;3720b124-a761-47b8-89b6-f2e2962add44)

Sorry, we can't find the page you are looking for.
* Running on local URL:  http://127.0.0.1:7865
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://0edfa698b720e905ce.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[9]:
ğŸ† Winning Titles Word Cloud

For every gold, silver, or bronze â€” thereâ€™s a title that held your victory.

This word cloud stitches together the names of all competitions where you medaled. The more a phrase shows up, the bigger it appears. Simple. Striking. Powerful.

ğŸ¯ Why this matters:
Because our strengths often echo in the titles weâ€™ve conquered. Maybe you didnâ€™t realize you kept winning in forecasting, or always landed a medal in computer vision. This lets you see it, in one glance â€” your niche, your patterns, your anthem. ğŸ’¬ Titles tell a story.
This one? It tells yours.
In [10]:
import matplotlib.pyplot as plt
def winning_titles_wordcloud(username):
    MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")

    # Load user ID
    users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
    user_id = users.loc[users["UserName"] == username, "Id"].values[0]

    # Get team memberships
    memberships = pd.read_csv(f"{MK_PATH}/TeamMemberships.csv", usecols=["TeamId", "UserId"])
    user_teams = memberships[memberships["UserId"] == user_id]["TeamId"].unique()

    # Get medal-winning competitions
    teams = pd.read_csv(f"{MK_PATH}/Teams.csv", usecols=["Id", "Medal", "CompetitionId"], low_memory=False)
    medal_teams = teams[(teams["Id"].isin(user_teams)) & (teams["Medal"].notna())]

    competitions = pd.read_csv(f"{MK_PATH}/Competitions.csv", usecols=["Id", "Title"])
    merged = medal_teams.merge(competitions, left_on="CompetitionId", right_on="Id", how="left")

    # Generate WordCloud
    text = " ".join(merged["Title"].dropna().tolist())
    wc = WordCloud(width=1000, height=500, background_color="black", colormap="Set2").generate(text)

    # Plot and return the figure
    fig, ax = plt.subplots(figsize=(12, 6))
    ax.imshow(wc, interpolation="bilinear")
    ax.axis("off")
    ax.set_title(f"{username}'s Winning Competition Keywords", color="white", fontsize=16)
    fig.tight_layout()
    return fig

gr.Interface(
    fn=winning_titles_wordcloud,
    inputs=gr.Textbox(label="ğŸ‘¤ Enter Kaggle Username"),
    outputs=gr.Plot(label="ğŸ† Winning Title Word Cloud"),
    title="ğŸ† Winning Competition Titles Word Cloud",
    description="Get a glimpse into the themes and titles of competitions where you earned medals.",
    theme="dark"
).launch()
/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1195: UserWarning:

Cannot load dark. Caught Exception: 404 Client Error: Not Found for url: https://huggingface.co/api/spaces/dark (Request ID: Root=1-68863e4c-5632a7b904544a253008a21f;328f93dc-16fb-430f-9d93-9801ea37fae2)

Sorry, we can't find the page you are looking for.
* Running on local URL:  http://127.0.0.1:7866
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://f3ef0a90a499e27cd5.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[10]:
ğŸ“ˆ Medal Progression Timeline

This isnâ€™t just a line plot. This is your Kaggle heartbeat.

Every medal youâ€™ve earned â€” Gold, Silver, Bronze â€” timestamped and traced across months. Whether it was a late-night submission or a comeback comp, it all adds up here.

ğŸ¯ Why this matters:
Because momentum is invisible... until you map it. This timeline shows how your effort evolved, where you peaked, and when you pushed through. Youâ€™ll notice:
â€¢ That first medal youâ€™ll never forget
â€¢ The gap months (burnout is real, and thatâ€™s okay)
â€¢ The seasons when you soared

ğŸ›¤ï¸ This is your medal journey, not just numbers on a plot. Look back and realize how far youâ€™ve come.
In [11]:
def medals_over_time(username):
    MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")

    # Load user ID
    users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
    user_id = users.loc[users["UserName"] == username, "Id"].values[0]

    # Get user's teams
    memberships = pd.read_csv(f"{MK_PATH}/TeamMemberships.csv", usecols=["TeamId", "UserId"])
    user_teams = memberships[memberships["UserId"] == user_id]["TeamId"].unique()

    # Get medals with dates
    teams = pd.read_csv(
        f"{MK_PATH}/Teams.csv",
        usecols=["Id", "Medal", "MedalAwardDate"],
        low_memory=False
    )
    teams = teams[teams["Id"].isin(user_teams)]
    teams["Medal"] = pd.to_numeric(teams["Medal"], errors="coerce")
    medal_map = {1: "Gold", 2: "Silver", 3: "Bronze"}
    teams["Medal"] = teams["Medal"].map(medal_map)
    teams["MedalAwardDate"] = pd.to_datetime(teams["MedalAwardDate"], errors="coerce")
    teams = teams.dropna(subset=["MedalAwardDate", "Medal"])

    # Group by month
    teams["Month"] = teams["MedalAwardDate"].dt.to_period("M").astype(str)
    timeline = teams.groupby(["Month", "Medal"]).size().reset_index(name="Count")

    # Plot
    fig = px.line(
        timeline,
        x="Month",
        y="Count",
        color="Medal",
        markers=True,
        title=f"{username}'s Medal Timeline",
        color_discrete_map={"Gold": "#FFD700", "Silver": "#C0C0C0", "Bronze": "#cd7f32"}
    )
    fig.update_layout(template="plotly_dark", xaxis_title="Month", yaxis_title="Number of Medals")
    return fig

gr.Interface(
    fn=medals_over_time,
    inputs=gr.Textbox(label="ğŸ‘¤ Enter Kaggle Username"),
    outputs=gr.Plot(label="ğŸ“ˆ Medal Timeline"),
    title="ğŸ… Medal Progression Timeline",
    description="See how the user's Kaggle medal journey has evolved over time.",
    theme="dark"
).launch()
/usr/local/lib/python3.11/dist-packages/gradio/blocks.py:1195: UserWarning:

Cannot load dark. Caught Exception: 404 Client Error: Not Found for url: https://huggingface.co/api/spaces/dark (Request ID: Root=1-68863e4e-6362006d05e475bb766988c9;b99f621a-9e12-4a03-b8af-1134960cdee3)

Sorry, we can't find the page you are looking for.
* Running on local URL:  http://127.0.0.1:7867
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://70ae036b75c08d23e8.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[11]:
ğŸŒ Your Competition Clusters
Every Kaggle competition you've explored falls under a specific domain â€” from geospatial analysis to NLP. But what if you could see all those domains visually clustered based on their themes?
This UMAP projection reduces high-dimensional tag-based features of competitions into a 2D plot. What emerges is a beautiful constellation â€” showing which areas of data science you've gravitated toward.
ğŸ“Œ UMAP embeddings based on domain tags from your Kaggle competition history.
ğŸ§ª Try it now!
Enter your Kaggle username and see your competition journey unfold in clusters.
In [12]:
import umap
def umap_competition_clusters(username):
    try:
        MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")
        users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
        user_id = users.loc[users["UserName"] == username, "Id"].values[0]

        competitions = pd.read_csv(f"{MK_PATH}/Competitions.csv", usecols=["Id", "Title", "HostSegmentTitle"])
        competition_tags = pd.read_csv(f"{MK_PATH}/CompetitionTags.csv", usecols=["CompetitionId", "TagId"])
        tags = pd.read_csv(f"{MK_PATH}/Tags.csv", usecols=["Id", "Name"])
        tag_map = dict(zip(tags["Id"], tags["Name"]))

        comp_tagged = competition_tags.merge(competitions, left_on="CompetitionId", right_on="Id")
        comp_tagged["TagName"] = comp_tagged["TagId"].map(tag_map)
        domain_map = comp_tagged.groupby("CompetitionId")["TagName"].agg(
            lambda x: x.mode().iloc[0] if not x.mode().empty else None
        )
        competitions["Domain"] = competitions["Id"].map(domain_map)

        domain_encoded = pd.get_dummies(competitions["Domain"])
        reducer = umap.UMAP(random_state=42)
        umap_embeddings = reducer.fit_transform(domain_encoded.fillna(0))
        umap_df = pd.DataFrame(umap_embeddings, columns=["x", "y"])
        umap_df["Domain"] = competitions["Domain"]
        umap_df["Title"] = competitions["Title"]

        fig = px.scatter(
            umap_df,
            x="x",
            y="y",
            color="Domain",
            hover_data=["Title"],
            title="ğŸ“Œ Competition Clusters (UMAP)"
        )
        fig.update_layout(template="plotly_dark")
        return fig

    except Exception as e:
        # In case of error, return an empty plot with the error message as title
        return px.scatter(title=f"âŒ Error: {e}")

# Gradio Interface
markdown_desc = """
<div style="background-color:#1c1c1c; padding: 25px; border-radius: 12px; border: 1px solid #333; margin-bottom: 30px">
<h2 style="color: #90ee90; margin-bottom: 12px;">ğŸŒ Your Competition Clusters</h2>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
Every Kaggle competition you've explored falls under a specific <strong style="color:#FFD700;">domain</strong> â€” from geospatial analysis to NLP.
But what if you could see all those domains <em>visually clustered</em> based on their themes?
</p>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
This UMAP projection reduces high-dimensional tag-based features of competitions into a 2D plot. What emerges is a beautiful constellation â€” showing which areas of data science you've gravitated toward.
</p>

<hr style="border: none; height: 1px; background: #333; margin: 25px 0;" />

<p style="color: #bbb; font-size: 14px;">
ğŸ“Œ UMAP embeddings based on domain tags from your Kaggle competition history.
</p>

<h4 style="color: #90ee90; margin-top: 25px;">ğŸ§ª Try it now!</h4>
<p style="color: #bbb; font-size: 15px;">
Enter your Kaggle username and see your competition journey unfold in clusters.
</p>
</div>
"""

gr.Interface(
    fn=umap_competition_clusters,
    inputs=gr.Textbox(label="Enter your Kaggle Username"),
    outputs=gr.Plot(label="ğŸ“Œ UMAP Competition Domains"),
    title="Kaggle UMAP Domain Clusters",
    description=markdown_desc,
    theme=gr.themes.Base()
).launch()
* Running on local URL:  http://127.0.0.1:7868
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://197df3ad922b5a3d19.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[12]:
ğŸ§  Your Notebook Language Palette
Every coder has a native tongue â€” this pie chart captures yours. Whether you speak in Pythonic elegance or whisper in R, this visualization reveals the distribution of languages across your published notebooks.
Language isn't just syntax â€” itâ€™s storytelling. And this chart showcases which stories youâ€™ve chosen to tell the most.
ğŸ“Š Pie chart showing language frequency across your kernel versions Â· Extracted from KernelVersions.csv and KernelLanguages.csv.
ğŸ§ª Curious what your dominant language is?
Enter your Kaggle handle below and discover the dialect of your data science.
In [13]:
def notebook_language_pie(username):
    try:
        # Load datasets
        MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")
        users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
        user_id = users.loc[users["UserName"] == username, "Id"].values[0]

        # Kernel stats
        kernel_versions = pd.read_csv(f"{MK_PATH}/KernelVersions.csv", low_memory=False)
        kernels = pd.read_csv(f"{MK_PATH}/Kernels.csv", usecols=["Id", "AuthorUserId", "Medal"])
        languages = pd.read_csv(f"{MK_PATH}/KernelLanguages.csv", usecols=["Id", "DisplayName"])

        user_kernel_versions = kernel_versions[kernel_versions["AuthorUserId"] == user_id]
        user_kernels = kernels[kernels["AuthorUserId"] == user_id]

        user_kernel_versions = user_kernel_versions.merge(
            languages, left_on="ScriptLanguageId", right_on="Id", how="left"
        ).rename(columns={"DisplayName": "Language"}).drop(columns=["Id_y"])

        user_kernel_versions = user_kernel_versions.merge(
            user_kernels[["Id", "Medal"]], left_on="ScriptId", right_on="Id", how="left"
        ).drop(columns=["Id"])

        # Pie chart
        lang_counts = user_kernel_versions["Language"].value_counts().reset_index()
        lang_counts.columns = ["Language", "Count"]
        fig = px.pie(lang_counts, names="Language", values="Count", title="ğŸ§  Language Usage in Notebooks")
        fig.update_layout(template="plotly_dark")

        return fig

    except Exception as e:
        return f"âŒ Error: {e}"

# Markdown for Gradio description
markdown_desc = """
<div style="background-color:#1c1c1c; padding: 25px; border-radius: 12px; border: 1px solid #333; margin-bottom: 30px">
<h2 style="color: #87CEEB; margin-bottom: 12px;">ğŸ§  Your Notebook Language Palette</h2>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
Every coder has a native tongue â€” this pie chart captures yours. Whether you speak in <strong style="color:#FFA07A;">Pythonic elegance</strong> or whisper in <strong style="color:#98FB98;">R</strong>, this visualization reveals the distribution of languages across your published notebooks.
</p>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
Language isn't just syntax â€” itâ€™s storytelling. And this chart showcases which stories youâ€™ve chosen to tell the most.
</p>

<hr style="border: none; height: 1px; background: #333; margin: 25px 0;" />

<p style="color: #bbb; font-size: 14px;">
ğŸ“Š Pie chart showing language frequency across your kernel versions Â· Extracted from <code>KernelVersions.csv</code> and <code>KernelLanguages.csv</code>.
</p>

<h4 style="color: #87CEEB; margin-top: 25px;">ğŸ§ª Curious what your dominant language is?</h4>
<p style="color: #bbb; font-size: 15px;">
Enter your Kaggle handle below and discover the dialect of your data science.
</p>
</div>
"""

# Gradio app
gr.Interface(
    fn=notebook_language_pie,
    inputs=gr.Textbox(label="Enter your Kaggle Username"),
    outputs=gr.Plot(label="ğŸ§  Notebook Language Usage"),
    title="Notebook Language Usage Â· Meta Kaggle",
    description=markdown_desc,
    theme=gr.themes.Base()
).launch()
* Running on local URL:  http://127.0.0.1:7869
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://b364cd34ebdacddb7c.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[13]:
ğŸ“ˆ Code Length Over Time
Behind every successful notebook is a growing codebase â€” evolving, expanding, and experimenting. This graph tracks your code length trends over time, across all languages you've used.
From short scripts to lengthy deep dives, this timeline visualizes how your coding journey has scaled in size and ambition.
ğŸ“Š Line chart grouped by notebook language Â· Based on EvaluationDate and TotalLines from KernelVersions.csv.
ğŸ§¬ Curious how your codebase has evolved?
Drop in your Kaggle username and watch your coding graph grow â€” one line at a time.
In [14]:
def code_length_trend(username):
    try:
        # Load data
        MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")
        users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
        user_id = users.loc[users["UserName"] == username, "Id"].values[0]

        kernel_versions = pd.read_csv(f"{MK_PATH}/KernelVersions.csv", low_memory=False)
        kernels = pd.read_csv(f"{MK_PATH}/Kernels.csv", usecols=["Id", "AuthorUserId", "Medal"])
        languages = pd.read_csv(f"{MK_PATH}/KernelLanguages.csv", usecols=["Id", "DisplayName"])

        # Filter user data
        user_kernel_versions = kernel_versions[kernel_versions["AuthorUserId"] == user_id]
        user_kernels = kernels[kernels["AuthorUserId"] == user_id]

        # Merge for language and medals
        user_kernel_versions = user_kernel_versions.merge(
            languages, left_on="ScriptLanguageId", right_on="Id", how="left"
        ).rename(columns={"DisplayName": "Language"}).drop(columns=["Id_y"])

        user_kernel_versions = user_kernel_versions.merge(
            user_kernels[["Id", "Medal"]], left_on="ScriptId", right_on="Id", how="left"
        ).drop(columns=["Id"])

        # Time trend analysis
        user_kernel_versions["EvaluationDate"] = pd.to_datetime(user_kernel_versions["EvaluationDate"], errors="coerce")
        code_trend = user_kernel_versions.dropna(subset=["EvaluationDate"]).sort_values("EvaluationDate")

        # Plot
        fig = px.line(
            code_trend, 
            x="EvaluationDate", 
            y="TotalLines", 
            color="Language", 
            title="ğŸ“ˆ Code Length Over Time"
        )
        fig.update_layout(template="plotly_dark")
        return fig

    except Exception as e:
        return f"âŒ Error: {e}"

# Styled markdown description
markdown_desc = """
<div style="background-color:#1c1c1c; padding: 25px; border-radius: 12px; border: 1px solid #333; margin-bottom: 30px">
<h2 style="color: #FFD700; margin-bottom: 12px;">ğŸ“ˆ Code Length Over Time</h2>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
Behind every successful notebook is a growing codebase â€” evolving, expanding, and experimenting.  
This graph tracks your <strong style="color:#FFD700;">code length trends</strong> over time, across all languages you've used.
</p>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
From short scripts to lengthy deep dives, this timeline visualizes how your coding journey has scaled in size and ambition.
</p>

<hr style="border: none; height: 1px; background: #333; margin: 25px 0;" />

<p style="color: #bbb; font-size: 14px;">
ğŸ“Š Line chart grouped by notebook language Â· Based on <code>EvaluationDate</code> and <code>TotalLines</code> from <code>KernelVersions.csv</code>.
</p>

<h4 style="color: #90ee90; margin-top: 25px;">ğŸ§¬ Curious how your codebase has evolved?</h4>
<p style="color: #bbb; font-size: 15px;">
Drop in your Kaggle username and watch your coding graph grow â€” one line at a time.
</p>
</div>
"""

# Gradio interface
gr.Interface(
    fn=code_length_trend,
    inputs=gr.Textbox(label="Enter your Kaggle Username"),
    outputs=gr.Plot(label="ğŸ“ˆ Code Length Over Time"),
    title="Code Length Timeline Â· Meta Kaggle",
    description=markdown_desc,
    theme=gr.themes.Base()
).launch()
* Running on local URL:  http://127.0.0.1:7870
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://7794d5dee53de283e6.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[14]:
ğŸ“Š Median Lines Per Notebook
Not all notebooks are created equal. Some are quick experiments, while others are robust pipelines. This chart gives you a language-wise breakdown of the typical notebook length, using the median to cut through outliers.
From Python-heavy notebooks to R or even RMarkdown scripts, see which language hosts your longest narratives.
ğŸ“Š Bar chart using TotalLines column from KernelVersions.csv Â· Median values grouped by Language
ğŸ“ Curious how verbose your notebooks tend to be?
Pop in your Kaggle handle and get a crisp breakdown â€” language by language.
In [15]:
def median_lines_by_language(username):
    try:
        # Load Meta Kaggle data
        MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")
        users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
        user_id = users.loc[users["UserName"] == username, "Id"].values[0]

        kernel_versions = pd.read_csv(f"{MK_PATH}/KernelVersions.csv", low_memory=False)
        kernels = pd.read_csv(f"{MK_PATH}/Kernels.csv", usecols=["Id", "AuthorUserId", "Medal"])
        languages = pd.read_csv(f"{MK_PATH}/KernelLanguages.csv", usecols=["Id", "DisplayName"])

        user_kernel_versions = kernel_versions[kernel_versions["AuthorUserId"] == user_id]
        user_kernels = kernels[kernels["AuthorUserId"] == user_id]

        user_kernel_versions = user_kernel_versions.merge(
            languages, left_on="ScriptLanguageId", right_on="Id", how="left"
        ).rename(columns={"DisplayName": "Language"}).drop(columns=["Id_y"])

        user_kernel_versions = user_kernel_versions.merge(
            user_kernels[["Id", "Medal"]], left_on="ScriptId", right_on="Id", how="left"
        ).drop(columns=["Id"])

        # Compute median lines
        median_lines = user_kernel_versions.groupby("Language")["TotalLines"].median().reset_index()
        median_lines.columns = ["Language", "MedianLines"]

        # Plot
        fig = px.bar(
            median_lines,
            x="Language",
            y="MedianLines",
            color="Language",
            title="ğŸ“Š Median Lines Per Notebook"
        )
        fig.update_layout(template="plotly_dark")
        return fig

    except Exception as e:
        return f"âŒ Error: {e}"

# Styled Markdown for this analysis
markdown_desc = """
<div style="background-color:#1c1c1c; padding: 25px; border-radius: 12px; border: 1px solid #333; margin-bottom: 30px">

<h2 style="color: #FFD700; margin-bottom: 12px;">ğŸ“Š Median Lines Per Notebook</h2>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
Not all notebooks are created equal. Some are quick experiments, while others are robust pipelines.  
This chart gives you a <strong style="color:#FFD700;">language-wise breakdown</strong> of the typical notebook length, using the median to cut through outliers.
</p>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
From Python-heavy notebooks to R or even RMarkdown scripts, see which language hosts your longest narratives.
</p>

<hr style="border: none; height: 1px; background: #333; margin: 25px 0;" />

<p style="color: #bbb; font-size: 14px;">
ğŸ“Š Bar chart using <code>TotalLines</code> column from <code>KernelVersions.csv</code> Â· Median values grouped by <code>Language</code>
</p>

<h4 style="color: #90ee90; margin-top: 25px;">ğŸ“ Curious how verbose your notebooks tend to be?</h4>
<p style="color: #bbb; font-size: 15px;">
Pop in your Kaggle handle and get a crisp breakdown â€” language by language.
</p>
</div>
"""

# Gradio interface
gr.Interface(
    fn=median_lines_by_language,
    inputs=gr.Textbox(label="Enter your Kaggle Username"),
    outputs=gr.Plot(label="ğŸ“Š Median Lines Per Notebook"),
    title="Notebook Length by Language Â· Meta Kaggle",
    description=markdown_desc,
    theme=gr.themes.Base()
).launch()
* Running on local URL:  http://127.0.0.1:7871
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://992a92e89e3bd5d371.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[15]:
ğŸ… Code Length by Medal Type
Do longer notebooks earn better medals? Or does quality beat quantity? This plot puts your medal-winning notebooks side by side, letting you compare code length across Gold, Silver, and Bronze submissions.
Outliers, patterns, and the occasional monster notebook â€” itâ€™s all visualized here. Each point is a submission. Each box tells its story.
ğŸ“¦ Based on TotalLines from KernelVersions.csv Â· Mapped via Medal in Kernels.csv
ğŸ“ˆ Ready to see how your Golds stack up?
Enter your Kaggle username and dive into the anatomy of your medal-winning code!
In [16]:
def code_length_by_medal(username):
    try:
        # Load Meta Kaggle data
        MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")
        users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
        user_id = users.loc[users["UserName"] == username, "Id"].values[0]

        kernel_versions = pd.read_csv(f"{MK_PATH}/KernelVersions.csv", low_memory=False)
        kernels = pd.read_csv(f"{MK_PATH}/Kernels.csv", usecols=["Id", "AuthorUserId", "Medal"])
        languages = pd.read_csv(f"{MK_PATH}/KernelLanguages.csv", usecols=["Id", "DisplayName"])

        user_kernel_versions = kernel_versions[kernel_versions["AuthorUserId"] == user_id]
        user_kernels = kernels[kernels["AuthorUserId"] == user_id]

        user_kernel_versions = user_kernel_versions.merge(
            languages, left_on="ScriptLanguageId", right_on="Id", how="left"
        ).rename(columns={"DisplayName": "Language"}).drop(columns=["Id_y"])

        user_kernel_versions = user_kernel_versions.merge(
            user_kernels[["Id", "Medal"]], left_on="ScriptId", right_on="Id", how="left"
        ).drop(columns=["Id"])

        # Map medals
        medal_map = {1: "Gold", 2: "Silver", 3: "Bronze"}
        user_kernel_versions["MedalType"] = user_kernel_versions["Medal"].map(medal_map)

        # Plot boxplot
        fig = px.box(
            user_kernel_versions.dropna(subset=["MedalType"]),
            x="MedalType",
            y="TotalLines",
            color="MedalType",
            title="ğŸ… Code Length by Medal Type",
            points="all"
        )
        fig.update_layout(template="plotly_dark")
        return fig

    except Exception as e:
        return f"âŒ Error: {e}"

# Styled Markdown description
markdown_desc = """
<div style="background-color:#1c1c1c; padding: 25px; border-radius: 12px; border: 1px solid #333; margin-bottom: 30px">

<h2 style="color: #FFD700; margin-bottom: 12px;">ğŸ… Code Length by Medal Type</h2>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
Do longer notebooks earn better medals? Or does quality beat quantity?
This plot puts your medal-winning notebooks side by side, letting you compare <strong style="color:#FFD700;">code length across Gold, Silver, and Bronze</strong> submissions.
</p>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
Outliers, patterns, and the occasional monster notebook â€” itâ€™s all visualized here.  
Each point is a submission. Each box tells its story.
</p>

<hr style="border: none; height: 1px; background: #333; margin: 25px 0;" />

<p style="color: #bbb; font-size: 14px;">
ğŸ“¦ Based on <code>TotalLines</code> from <code>KernelVersions.csv</code> Â· Mapped via <code>Medal</code> in <code>Kernels.csv</code>
</p>

<h4 style="color: #90ee90; margin-top: 25px;">ğŸ“ˆ Ready to see how your Golds stack up?</h4>
<p style="color: #bbb; font-size: 15px;">
Enter your Kaggle username and dive into the anatomy of your medal-winning code!
</p>
</div>
"""

# Gradio Interface
gr.Interface(
    fn=code_length_by_medal,
    inputs=gr.Textbox(label="Enter your Kaggle Username"),
    outputs=gr.Plot(label="ğŸ… Code Length by Medal Type"),
    title="Code Length vs Medal Quality Â· Meta Kaggle",
    description=markdown_desc,
    theme=gr.themes.Base()
).launch()
* Running on local URL:  http://127.0.0.1:7872
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://f908bfbe1aac9a42f5.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[16]:
â˜ï¸ Word Cloud: Notebook Title Trends
Each notebook title you write whispers a story. This word cloud reveals the most frequent words that echo through your notebooks â€” from "XGBoost" to "EDA", from "Titanic" to "Transformer".
Your focus, favorite techniques, or even recurring competitions â€” itâ€™s all hidden in the words you choose to title your work.
ğŸ“ Titles sourced from KernelVersions.csv ğŸ¨ Visualized using wordcloud and matplotlib
ğŸ” What do your notebook titles reveal about you?
Enter your Kaggle username and see your themes take shape.
In [17]:
def notebook_title_wordcloud(username):
    try:
        # Load user ID
        MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")
        users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
        user_id = users.loc[users["UserName"] == username, "Id"].values[0]

        # Load kernel metadata
        kernel_versions = pd.read_csv(f"{MK_PATH}/KernelVersions.csv", low_memory=False)
        user_kernel_versions = kernel_versions[kernel_versions["AuthorUserId"] == user_id]

        # Extract titles
        titles = user_kernel_versions["Title"].dropna().tolist()
        if not titles:
            return "ğŸ«¥ No notebook titles found for this user."

        # Generate WordCloud
        wc = WordCloud(
            width=1000,
            height=500,
            background_color="black",
            colormap="Set2"
        ).generate(" ".join(titles))

        plt.figure(figsize=(12, 6))
        plt.imshow(wc, interpolation="bilinear")
        plt.axis("off")
        plt.title(f"{username}'s Notebook Title Keywords", color="white", fontsize=18)
        return plt.gcf()

    except Exception as e:
        return f"âŒ Error: {e}"

# Markdown Description
markdown_desc = """
<div style="background-color:#1c1c1c; padding: 25px; border-radius: 12px; border: 1px solid #333; margin-bottom: 30px">

<h2 style="color: #fcbf49;">â˜ï¸ Word Cloud: Notebook Title Trends</h2>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
Each notebook title you write whispers a story.  
This word cloud reveals <strong style="color:#fcbf49;">the most frequent words</strong> that echo through your notebooks â€” from "XGBoost" to "EDA", from "Titanic" to "Transformer".
</p>

<p style="color: #e0e0e0; font-size: 16px; line-height: 1.7;">
Your focus, favorite techniques, or even recurring competitions â€” itâ€™s all hidden in the words you choose to title your work.
</p>

<hr style="border: none; height: 1px; background: #333; margin: 25px 0;" />

<p style="color: #bbb; font-size: 14px;">
ğŸ“ Titles sourced from <code>KernelVersions.csv</code>  
ğŸ¨ Visualized using <code>wordcloud</code> and <code>matplotlib</code>
</p>

<h4 style="color: #90ee90; margin-top: 25px;">ğŸ” What do your notebook titles reveal about you?</h4>
<p style="color: #bbb; font-size: 15px;">
Enter your Kaggle username and see your themes take shape.
</p>
</div>
"""

# Gradio Interface
gr.Interface(
    fn=notebook_title_wordcloud,
    inputs=gr.Textbox(label="Enter your Kaggle Username"),
    outputs=gr.Plot(label="â˜ï¸ Notebook Title Word Cloud"),
    title="Notebook Title Word Cloud Â· Meta Kaggle",
    description=markdown_desc,
    theme=gr.themes.Base()
).launch()
* Running on local URL:  http://127.0.0.1:7873
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://b2a034f63684576c25.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[17]:
ğŸ¥§ Evaluation Strategies Pie

Ever paused to think how Kaggle *judges* you?
Behind every competition lies a carefully chosen evaluation metric â€” the real scoreboard that defines whether your submission ranks 1st or 101st.

ğŸ¯ What this shows:
This pie breaks down the **evaluation strategies** used in competitions youâ€™ve participated in â€” from RMSE to F1, from LogLoss to custom evaluation functions.

ğŸ” Why care?
Because understanding how you're evaluated sharpens how you compete.
If you're winning in LogLoss comps but rarely ranking in AUC ones, this chart whispers a story worth listening to.

Whether youâ€™re a ğŸ§  modeling purist or a ğŸ§ª competition junkie, this slice of insight helps align your strengths to the right leaderboard fights.
In [18]:
def evaluation_strategy_pie(username):
    MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")

    users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
    user_id = users.loc[users["UserName"] == username, "Id"].values[0]

    memberships = pd.read_csv(f"{MK_PATH}/TeamMemberships.csv", usecols=["TeamId", "UserId"])
    user_teams = memberships[memberships["UserId"] == user_id]["TeamId"].unique()

    teams = pd.read_csv(f"{MK_PATH}/Teams.csv", usecols=["Id", "CompetitionId", "Medal", "MedalAwardDate", "TeamLeaderId"])
    teams = teams[teams["Id"].isin(user_teams)]

    submissions = pd.read_csv(f"{MK_PATH}/Submissions.csv")
    competitions = pd.read_csv(f"{MK_PATH}/Competitions.csv")

    user_submissions = submissions[submissions["TeamId"].isin(user_teams)]
    user_submissions = user_submissions.merge(teams, left_on="TeamId", right_on="Id", suffixes=("", "_Team"))
    user_submissions = user_submissions.merge(competitions, left_on="CompetitionId", right_on="Id", suffixes=("", "_Comp"))

    first_submissions = user_submissions.sort_values("SubmissionDate").groupby("CompetitionId").first().reset_index()

    eval_counts = first_submissions["EvaluationAlgorithmName"].value_counts().reset_index()
    eval_counts.columns = ["EvaluationAlgorithmName", "Count"]

    fig = px.pie(eval_counts, values="Count", names="EvaluationAlgorithmName",
                 title="ğŸ§  Evaluation Strategies of Participated Competitions")
    fig.update_layout(template="plotly_dark")
    return fig

gr.Interface(
    fn=evaluation_strategy_pie,
    inputs=gr.Textbox(label="Enter your Kaggle Username"),
    outputs=gr.Plot(label="Evaluation Strategy Breakdown"),
    title="Kaggle Evaluation Algorithms Pie",
    theme=gr.themes.Base()
).launch()
* Running on local URL:  http://127.0.0.1:7874
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://51c5916dc54da5019c.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[18]:
ğŸ¥§ Evaluation Strategies Pie

Ever paused to think how Kaggle *judges* you?
Behind every competition lies a carefully chosen evaluation metric â€” the real scoreboard that defines whether your submission ranks 1st or 101st.

ğŸ¯ What this shows:
This pie breaks down the **evaluation strategies** used in competitions youâ€™ve participated in â€” from RMSE to F1, from LogLoss to custom evaluation functions.

ğŸ” Why care?
Because understanding how you're evaluated sharpens how you compete.
If you're winning in LogLoss comps but rarely ranking in AUC ones, this chart whispers a story worth listening to.

Whether youâ€™re a ğŸ§  modeling purist or a ğŸ§ª competition junkie, this slice of insight helps align your strengths to the right leaderboard fights.
In [19]:
def individual_vs_team_pie(username):
    MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")

    users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
    user_id = users.loc[users["UserName"] == username, "Id"].values[0]

    memberships = pd.read_csv(f"{MK_PATH}/TeamMemberships.csv", usecols=["TeamId", "UserId"])
    user_teams = memberships[memberships["UserId"] == user_id]["TeamId"].unique()

    teams = pd.read_csv(f"{MK_PATH}/Teams.csv", usecols=["Id", "CompetitionId", "Medal", "MedalAwardDate", "TeamLeaderId"])
    teams = teams[teams["Id"].isin(user_teams)]

    submissions = pd.read_csv(f"{MK_PATH}/Submissions.csv")
    competitions = pd.read_csv(f"{MK_PATH}/Competitions.csv")

    user_submissions = submissions[submissions["TeamId"].isin(user_teams)]
    user_submissions = user_submissions.merge(teams, left_on="TeamId", right_on="Id", suffixes=("", "_Team"))
    user_submissions = user_submissions.merge(competitions, left_on="CompetitionId", right_on="Id", suffixes=("", "_Comp"))

    first_submissions = user_submissions.sort_values("SubmissionDate").groupby("CompetitionId").first().reset_index()

    first_submissions["TeamType"] = first_submissions["EnableTeamModels"].map({True: "Team", False: "Individual"})
    team_counts = first_submissions["TeamType"].value_counts().reset_index()
    team_counts.columns = ["TeamType", "Count"]

    fig = px.pie(team_counts, values="Count", names="TeamType",
                 title="ğŸ‘¤ Individual vs ğŸ‘¥ Team Competitions")
    fig.update_layout(template="plotly_dark")
    return fig

gr.Interface(
    fn=individual_vs_team_pie,
    inputs=gr.Textbox(label="Enter your Kaggle Username"),
    outputs=gr.Plot(label="Team vs Individual Participation"),
    title="Team Participation Breakdown",
    theme=gr.themes.Base()
).launch()
* Running on local URL:  http://127.0.0.1:7875
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://2a46b9d51b1c5200d1.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[19]:
ğŸ·ï¸ Featured vs Research: What's Your Flavor?

Every Kaggler has a vibe. Some live for the thrill of **Featured competitions** â€” high stakes, big prizes, and leaderboard wars that feel like Formula 1. Others prefer the quieter elegance of **Research competitions** â€” where insight matters more than impact score.

ğŸ“Š This pie tells your type story.
Are you more of a leaderboard gladiator or a research explorer? This breakdown gives you a peek into the kind of competitions you've gravitated towards.

ğŸ¤” Why does it matter?
Because recognizing your **competition personality** can guide your next move â€” whether it's doubling down on your strength or stepping out of your comfort zone.

So... what's your dominant shade: ğŸŸ  Featured or ğŸ”µ Research?
In [20]:
def competition_type_pie(username):
    MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")

    users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
    user_id = users.loc[users["UserName"] == username, "Id"].values[0]

    memberships = pd.read_csv(f"{MK_PATH}/TeamMemberships.csv", usecols=["TeamId", "UserId"])
    user_teams = memberships[memberships["UserId"] == user_id]["TeamId"].unique()

    teams = pd.read_csv(f"{MK_PATH}/Teams.csv", usecols=["Id", "CompetitionId", "Medal", "MedalAwardDate", "TeamLeaderId"])
    teams = teams[teams["Id"].isin(user_teams)]

    submissions = pd.read_csv(f"{MK_PATH}/Submissions.csv")
    competitions = pd.read_csv(f"{MK_PATH}/Competitions.csv")

    user_submissions = submissions[submissions["TeamId"].isin(user_teams)]
    user_submissions = user_submissions.merge(teams, left_on="TeamId", right_on="Id", suffixes=("", "_Team"))
    user_submissions = user_submissions.merge(competitions, left_on="CompetitionId", right_on="Id", suffixes=("", "_Comp"))

    first_submissions = user_submissions.sort_values("SubmissionDate").groupby("CompetitionId").first().reset_index()

    comp_type_map = {1: "Featured", 2: "Research"}
    first_submissions["Type"] = first_submissions["CompetitionTypeId"].map(comp_type_map)
    type_counts = first_submissions["Type"].value_counts().reset_index()
    type_counts.columns = ["Type", "Count"]

    fig = px.pie(type_counts, values="Count", names="Type",
                 title="ğŸ·ï¸ Competition Types: Featured vs Research")
    fig.update_layout(template="plotly_dark")
    return fig

gr.Interface(
    fn=competition_type_pie,
    inputs=gr.Textbox(label="Enter your Kaggle Username"),
    outputs=gr.Plot(label="Competition Type Breakdown"),
    title="Competition Type Analysis",
    theme=gr.themes.Base()
).launch()
* Running on local URL:  http://127.0.0.1:7876
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://a6d2c1890798482d5c.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[20]:
ğŸ“… Forum Activity Timeline
Your footprints across Kaggle's forum are like journal entries of curiosity, help, and shared knowledge.
This timeline charts your posting frequency over time â€” showing your phases of intense help, community connection, or quiet observation.
In [21]:
def forum_activity_timeline(username):
    try:
        MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")
        users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
        user_id = users.loc[users["UserName"] == username, "Id"].values[0]

        messages = pd.read_csv(f"{MK_PATH}/ForumMessages.csv", usecols=["Id", "PostUserId", "PostDate"])
        user_msgs = messages[messages["PostUserId"] == user_id].copy()
        user_msgs["PostDate"] = pd.to_datetime(user_msgs["PostDate"])

        monthly = user_msgs.groupby(user_msgs["PostDate"].dt.to_period("M")).size().reset_index(name="Count")
        monthly["PostDate"] = monthly["PostDate"].dt.to_timestamp()

        fig = px.line(monthly, x="PostDate", y="Count", title="ğŸ“… Forum Activity Timeline")
        fig.update_layout(template="plotly_dark")
        return fig
    except Exception as e:
        return f"âŒ Error: {e}"

desc_1 = """
<div style="background:#1c1c1c;padding:25px;border-radius:12px;border:1px solid #333;">
<h2 style="color:#00e5ff;">ğŸ“… Forum Activity Timeline</h2>
<p style="color:#ccc;">Your footprints across Kaggle's forum are like journal entries of curiosity, help, and shared knowledge.</p>
<p style="color:#aaa;">This timeline charts your posting frequency over time â€” showing your phases of intense help, community connection, or quiet observation.</p>
</div>
"""

gr.Interface(
    fn=forum_activity_timeline,
    inputs=gr.Textbox(label="Enter Kaggle Username"),
    outputs=gr.Plot(label="Forum Activity Timeline"),
    title="Forum Timeline Â· Meta Kaggle",
    description=desc_1,
).launch()
* Running on local URL:  http://127.0.0.1:7877
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://50e4d405f7c6943027.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[21]:
div style="background:#1c1c1c;padding:25px;border-radius:12px;border:1px solid #333;">
â“ Question vs âœ… Answer
Do you ask the tough questions, or are you the torchbearer guiding others?
This pie chart reveals your role in the Kaggle community: inquisitor or mentor. Sometimes both. Always learning.
</div>
In [22]:
def question_vs_answer(username):
    try:
        MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")
        users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
        user_id = users.loc[users["UserName"] == username, "Id"].values[0]

        messages = pd.read_csv(f"{MK_PATH}/ForumMessages.csv", usecols=["PostUserId", "Message"])
        user_msgs = messages[messages["PostUserId"] == user_id].copy()
        user_msgs["IsQuestion"] = user_msgs["Message"].str.lower().str.contains(r"\b(how|why|what|where|when|\?)")

        counts = user_msgs["IsQuestion"].value_counts().rename(index={True: "Question", False: "Answer"}).reset_index()
        counts.columns = ["Type", "Count"]

        fig = px.pie(counts, names="Type", values="Count", title="â“ Question vs âœ… Answer Posts")
        fig.update_layout(template="plotly_dark")
        return fig
    except Exception as e:
        return f"âŒ Error: {e}"

desc_2 = """
<div style="background:#1c1c1c;padding:25px;border-radius:12px;border:1px solid #333;">
<h2 style="color:#ffcc00;">â“ Question vs âœ… Answer</h2>
<p style="color:#ccc;">Do you ask the tough questions, or are you the torchbearer guiding others?</p>
<p style="color:#aaa;">This pie chart reveals your role in the Kaggle community: inquisitor or mentor. Sometimes both. Always learning.</p>
</div>
"""

gr.Interface(
    fn=question_vs_answer,
    inputs=gr.Textbox(label="Enter Kaggle Username"),
    outputs=gr.Plot(label="QnA Breakdown"),
    title="Forum QnA Ratio Â· Meta Kaggle",
    description=desc_2,
).launch()
* Running on local URL:  http://127.0.0.1:7878
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://25ed15c1cac77bf0eb.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[22]:
ğŸŒŸ Upvoted Words from Forum Contributions
These arenâ€™t just words. Theyâ€™re echoes of appreciation.
Each term in this cloud surfaced from your most upvoted posts â€” the ideas that resonated, helped, or inspired the community.
In [23]:
def forum_wordcloud(username):
    try:
        MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")
        users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
        user_id = users.loc[users["UserName"] == username, "Id"].values[0]

        messages = pd.read_csv(f"{MK_PATH}/ForumMessages.csv", usecols=["Id", "PostUserId", "Message"])
        votes = pd.read_csv(f"{MK_PATH}/ForumMessageVotes.csv", usecols=["ForumMessageId", "ToUserId"])
        votes_user = votes[votes["ToUserId"] == user_id]
        vote_counts = votes_user["ForumMessageId"].value_counts().rename("VoteCount")

        user_msgs = messages[messages["PostUserId"] == user_id].copy()
        user_msgs = user_msgs.merge(vote_counts, left_on="Id", right_index=True, how="left").fillna(0)
        top_posts = user_msgs.sort_values("VoteCount", ascending=False).head(100)
        text = " ".join(top_posts["Message"].dropna().astype(str).tolist())

        wc = WordCloud(width=1000, height=500, background_color="black", colormap="Set2").generate(text)
        plt.figure(figsize=(12, 6))
        plt.imshow(wc, interpolation="bilinear")
        plt.axis("off")
        plt.title(f"{username}'s Most Upvoted Forum Words", color="white")
        return plt.gcf()
    except Exception as e:
        return f"âŒ Error: {e}"

desc_3 = """
<div style="background:#1c1c1c;padding:25px;border-radius:12px;border:1px solid #333;">
<h2 style="color:#90ee90;">ğŸŒŸ Upvoted Words from Forum Contributions</h2>
<p style="color:#ccc;">These arenâ€™t just words. Theyâ€™re echoes of appreciation.</p>
<p style="color:#aaa;">Each term in this cloud surfaced from your most upvoted posts â€” the ideas that resonated, helped, or inspired the community.</p>
</div>
"""

gr.Interface(
    fn=forum_wordcloud,
    inputs=gr.Textbox(label="Enter Kaggle Username"),
    outputs=gr.Plot(label="Forum Word Cloud"),
    title="Forum Word Cloud Â· Meta Kaggle",
    description=desc_3,
).launch()
* Running on local URL:  http://127.0.0.1:7879
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://fc0310e8bfe9d17908.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[23]:
ğŸ… Where Quality Meets Recognition
Every dataset isn't just a fileâ€”it's a contribution to the Kaggle community. This bar chart celebrates the ones that stood outâ€”earning gold, silver, or bronze medals. Itâ€™s a visual proof of impactful data work and the recognition it garnered.
In [24]:
def medaled_datasets_bar(username):
    MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")
    users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
    user_id = users.loc[users["UserName"] == username, "Id"].values[0]
    datasets = pd.read_csv(f"{MK_PATH}/Datasets.csv")
    user_datasets = datasets[datasets["OwnerUserId"] == user_id].copy()
    user_datasets["Medal"] = user_datasets["Medal"].map({1: "Gold", 2: "Silver", 3: "Bronze"})

    medal_counts = user_datasets["Medal"].value_counts().reset_index()
    medal_counts.columns = ["Medal", "Count"]
    fig = px.bar(medal_counts, x="Medal", y="Count", color="Medal", title="ğŸ… Medaled Datasets")
    fig.update_layout(template="plotly_dark")
    return fig

gr.Interface(fn=medaled_datasets_bar, inputs="text", outputs="plot", title="ğŸ… Medaled Datasets").launch()
* Running on local URL:  http://127.0.0.1:7880
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://3bb7a259509d619440.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[24]:
ğŸ“… A Timeline of Data Contributions
This line chart captures the creator's rhythmâ€”how consistently and passionately theyâ€™ve shared datasets over time. Peaks often indicate bursts of curiosity or competition-driven effort, forming a personal timeline of community impact.
In [25]:
def dataset_creation_timeline(username):
    MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")
    users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
    user_id = users.loc[users["UserName"] == username, "Id"].values[0]
    datasets = pd.read_csv(f"{MK_PATH}/Datasets.csv")
    user_datasets = datasets[datasets["OwnerUserId"] == user_id].copy()
    user_datasets["CreationDate"] = pd.to_datetime(user_datasets["CreationDate"])

    monthly = user_datasets.groupby(user_datasets["CreationDate"].dt.to_period("M")).size().reset_index(name="Count")
    monthly["CreationDate"] = monthly["CreationDate"].dt.to_timestamp()
    fig = px.line(monthly, x="CreationDate", y="Count", title="ğŸ“… Dataset Creation Timeline")
    fig.update_layout(template="plotly_dark")
    return fig

gr.Interface(fn=dataset_creation_timeline, inputs="text", outputs="plot", title="ğŸ“… Dataset Creation Timeline").launch()
* Running on local URL:  http://127.0.0.1:7881
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://7c7112be397ac3522c.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[25]:
ğŸ“Š The Echo of Community
How much a dataset resonates is measured by votes and downloads. This boxplot shows how certain datasets break the mold, becoming community favorites while others serve more niche purposes. A visual of reception, reach, and relevance.
In [26]:
def dataset_votes_downloads_boxplot(username):
    MK_PATH = kagglehub.dataset_download("kaggle/meta-kaggle")
    users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
    user_id = users.loc[users["UserName"] == username, "Id"].values[0]
    datasets = pd.read_csv(f"{MK_PATH}/Datasets.csv")
    user_datasets = datasets[datasets["OwnerUserId"] == user_id].copy()

    fig = px.box(user_datasets, y=["TotalVotes", "TotalDownloads"], title="ğŸ“Š Dataset Votes & Downloads")
    fig.update_layout(template="plotly_dark", yaxis_title="Count")
    return fig

gr.Interface(fn=dataset_votes_downloads_boxplot, inputs="text", outputs="plot", title="ğŸ“Š Dataset Votes & Downloads").launch()
* Running on local URL:  http://127.0.0.1:7882
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://e7a8c24e47ef5c6a94.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
Out[26]:
ğŸ“Š Skill Evolution Across Time & Contributions
Every tag tells a storyâ€”a hint about what {username} was exploring, mastering, or sharing at a given time. This multi-layered line plot captures the evolution of their top 10 skill domains, spanning competitions, notebooks, and datasets. The solid, dashed, and dotted lines represent different avenues of learning and contribution. Together, they paint a timeline of curiosity, consistency, and growth.
In [ ]:
def plot_skill_evolution(username):
    MK_PATH = "/kaggle/input/meta-kaggle"

    # Load user ID
    users = pd.read_csv(f"{MK_PATH}/Users.csv", usecols=["Id", "UserName"])
    user_id = users.loc[users["UserName"] == username, "Id"].values[0]

    tags = pd.read_csv(f"{MK_PATH}/Tags.csv", usecols=["Id", "Name"])

    #Competitions 
    teams = pd.read_csv(f"{MK_PATH}/Teams.csv", usecols=["Id", "TeamLeaderId", "CompetitionId", "MedalAwardDate"])
    teams = teams[teams["TeamLeaderId"] == user_id].dropna(subset=["MedalAwardDate"])
    teams["Date"] = pd.to_datetime(teams["MedalAwardDate"]).dt.to_period("M").dt.to_timestamp()

    comp_tags = pd.read_csv(f"{MK_PATH}/CompetitionTags.csv", usecols=["CompetitionId", "TagId"])
    comp_tags = comp_tags[comp_tags["CompetitionId"].isin(teams["CompetitionId"])]
    comp_tags = comp_tags.merge(teams[["CompetitionId", "Date"]], on="CompetitionId", how="left")
    comp_tags = comp_tags.merge(tags, left_on="TagId", right_on="Id", how="left")
    comp_tags["Source"] = "Competitions"

    #  Notebooks
    kernels = pd.read_csv(f"{MK_PATH}/Kernels.csv", usecols=["Id", "AuthorUserId", "CreationDate"])
    kernels = kernels[kernels["AuthorUserId"] == user_id]
    kernels["Date"] = pd.to_datetime(kernels["CreationDate"]).dt.to_period("M").dt.to_timestamp()

    kernel_tags = pd.read_csv(f"{MK_PATH}/KernelTags.csv", usecols=["KernelId", "TagId"])
    kernel_tags = kernel_tags[kernel_tags["KernelId"].isin(kernels["Id"])]
    kernel_tags = kernel_tags.merge(kernels[["Id", "Date"]], left_on="KernelId", right_on="Id", how="left")
    kernel_tags = kernel_tags.merge(tags, left_on="TagId", right_on="Id", how="left")
    kernel_tags["Source"] = "Notebooks"

    # Datasets 
    dsv = pd.read_csv(f"{MK_PATH}/DatasetVersions.csv", usecols=["Id", "DatasetId", "CreatorUserId", "CreationDate"])
    dsv = dsv[dsv["CreatorUserId"] == user_id]
    dsv["Date"] = pd.to_datetime(dsv["CreationDate"]).dt.to_period("M").dt.to_timestamp()

    dataset_tags = pd.read_csv(f"{MK_PATH}/DatasetTags.csv", usecols=["DatasetId", "TagId"])
    dataset_tags = dataset_tags[dataset_tags["DatasetId"].isin(dsv["DatasetId"])]
    dataset_tags = dataset_tags.merge(dsv[["DatasetId", "Date"]], on="DatasetId", how="left")
    dataset_tags = dataset_tags.merge(tags, left_on="TagId", right_on="Id", how="left")
    dataset_tags["Source"] = "Datasets"

    # Combine & Filter
    combined = pd.concat([
        comp_tags[["Date", "Name", "Source"]],
        kernel_tags[["Date", "Name", "Source"]],
        dataset_tags[["Date", "Name", "Source"]]
    ])

    top_tags = combined["Name"].value_counts().head(10).index
    combined = combined[combined["Name"].isin(top_tags)]

    evolution = combined.groupby(["Date", "Name", "Source"]).size().reset_index(name="Count")

    # â”€â”€â”€â”€â”€â”€â”€ Plot â”€â”€â”€â”€â”€â”€â”€
    fig = px.line(
        evolution, x="Date", y="Count", color="Name", line_dash="Source", markers=True,
        title=f"ğŸ“Š Skill Evolution of {username} via Competitions, Notebooks, Datasets",
        labels={"Date": "Month", "Count": "Mentions", "Name": "Skill Tag"}
    )
    fig.update_layout(template="plotly_dark", height=600)

    # Markdown
    markdown = f"""
<div style="padding: 1rem; background-color: #1e1e1e; color: white; border-left: 4px solid #00cc99; margin-bottom: 1rem;">
    <h3>ğŸ“Š Skill Evolution Across Time & Contributions</h3>
    <p>Every tag tells a storyâ€”a hint about what <strong>{username}</strong> was exploring, mastering, or sharing at a given time. 
    This multi-layered line plot captures the evolution of their top 10 skill domains, spanning competitions, notebooks, and datasets. 
    The solid, dashed, and dotted lines represent different avenues of learning and contribution. 
    Together, they paint a timeline of curiosity, consistency, and growth.</p>
</div>
"""
    return markdown, fig

# Gradio Interface
demo = gr.Interface(
    fn=plot_skill_evolution,
    inputs=gr.Textbox(label="Enter Kaggle Username", value="christofhenkel"),
    outputs=[gr.HTML(), gr.Plot()],
    title="ğŸ“ˆ Kaggle Skill Tag Evolution",
    description="Explore how a Kaggle user's expertise evolved across competitions, notebooks, and datasets using their top skill tags over time."
)

demo.launch(debug=True)
* Running on local URL:  http://127.0.0.1:7883
It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).

* Running on public URL: https://be6a8487f0c4bf1235.gradio.live

This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)
modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]
config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]
README.md: 0.00B [00:00, ?B/s]
sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]
config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]
model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]
tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]
vocab.txt: 0.00B [00:00, ?B/s]
tokenizer.json: 0.00B [00:00, ?B/s]
special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]
config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]
Batches:   0%|          | 0/308 [00:00<?, ?it/s]
Batches:   0%|          | 0/77 [00:00<?, ?it/s]
Batches:   0%|          | 0/77 [00:00<?, ?it/s]
/usr/local/lib/python3.11/dist-packages/umap/umap_.py:1952: UserWarning:

n_jobs value 1 overridden to 1 by setting random_state. Use no seed for parallelism.

/tmp/ipykernel_35/2345609835.py:13: DtypeWarning:

Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.

/tmp/ipykernel_35/409898241.py:13: DtypeWarning:

Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.

/tmp/ipykernel_35/1400534485.py:13: DtypeWarning:

Columns (7) have mixed types. Specify dtype option on import or set low_memory=False.

/tmp/ipykernel_35/2018460016.py:9: UserWarning:

This pattern is interpreted as a regular expression, and has match groups. To actually get the groups, use str.extract.

/tmp/ipykernel_35/1077108307.py:5: DtypeWarning:

Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.

/tmp/ipykernel_35/2545770044.py:5: DtypeWarning:

Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.

/tmp/ipykernel_35/1533356536.py:5: DtypeWarning:

Columns (15) have mixed types. Specify dtype option on import or set low_memory=False.
ğŸ¯ Letâ€™s Talk Discovery: Your Next Competition Might Already Be Calling

Kaggle isn't just a place for leaderboard chases â€” itâ€™s a universe of ideas, domains, and themes waiting to be explored. But with hundreds of competitions, how do you find the ones that **truly align with your interests**?

ğŸ§  Enter TF-IDF + Cosine Similarity
We build a fingerprint of your past competitions using their tags, and then scan the entire landscape to find **thematic matches** you havenâ€™t joined yet. This isnâ€™t just about suggesting popular ones â€” itâ€™s about finding what resonates with *your data science identity*.

âš¡ Whatâ€™s Under the Hood?
Weâ€™re merging tags, vectorizing them, computing cosine similarity, and filtering out the competitions you've already tackled. The result? A **personalized shortlist** of challenges that speak your language â€” whether it's NLP, vision, forecasting, or genomics.

ğŸš€ Ready to jump into your next best match?
In [31]:
# File path base
BASE_PATH = '/kaggle/input/meta-kaggle'

# Load necessary data
competitions = pd.read_csv(f"{BASE_PATH}/Competitions.csv", usecols=['Id', 'Title'])
competition_tags = pd.read_csv(f"{BASE_PATH}/CompetitionTags.csv", usecols=['CompetitionId', 'TagId'])
tags = pd.read_csv(f"{BASE_PATH}/Tags.csv", usecols=['Id', 'Name'])
teams = pd.read_csv(f"{BASE_PATH}/Teams.csv", usecols=['Id', 'CompetitionId'])
memberships = pd.read_csv(f"{BASE_PATH}/TeamMemberships.csv", usecols=['TeamId', 'UserId'])

# Merge tags with tag names
competition_tags = competition_tags.merge(tags, left_on='TagId', right_on='Id', how='left')
competition_tags = competition_tags[['CompetitionId', 'Name']]

# Group tags by competition
comp_tags_agg = competition_tags.groupby('CompetitionId')['Name'].apply(lambda x: ' '.join(x)).reset_index()
comp_tags_agg.columns = ['CompetitionId', 'Tags']

# Merge with competition titles
comp_df = competitions.merge(comp_tags_agg, left_on='Id', right_on='CompetitionId', how='left')
comp_df['Tags'] = comp_df['Tags'].fillna('')

# Optional: sample to avoid OOM
#comp_df = comp_df.sample(n=10000, random_state=42).reset_index(drop=True)
comp_df = comp_df.sample(n=min(10000, len(comp_df)), random_state=42).reset_index(drop=True)

# Build user â†’ competition history
team_comp_map = teams[['Id', 'CompetitionId']].rename(columns={'Id': 'TeamId'})
user_teams = memberships.merge(team_comp_map, on='TeamId', how='left')

# Choose user (make sure they exist)
user_id = 1473553  # <-- change this if needed
user_comp_ids = user_teams[user_teams['UserId'] == user_id]['CompetitionId'].dropna().unique()

# Filter to competitions in sample
user_comp_ids = list(set(user_comp_ids) & set(comp_df['Id']))

if not user_comp_ids:
    print(f"âš ï¸ No competitions found for user {user_id} in the current dataset sample.")
else:
    # Build user profile from tags
    user_tags = comp_df[comp_df['Id'].isin(user_comp_ids)]['Tags'].str.cat(sep=' ')

    # TF-IDF vectorizer
    vectorizer = TfidfVectorizer()
    tfidf_matrix = vectorizer.fit_transform(comp_df['Tags'])
    user_vec = vectorizer.transform([user_tags])

    # Compute cosine similarity
    comp_df['Similarity'] = cosine_similarity(user_vec, tfidf_matrix).flatten()

    # Exclude competitions already participated in
    recommended = comp_df[~comp_df['Id'].isin(user_comp_ids)].sort_values(by='Similarity', ascending=False)

    # Show top 10 recommendations
    print(f"\nğŸ¯ Top Competition Recommendations for User {user_id}:\n")
    display(recommended[['Title', 'Tags', 'Similarity']].head(10))
ğŸ¯ Top Competition Recommendations for User 1473553:
Title Tags Similarity
9180 Ghouls, Goblins, and Ghosts... Boo! tabular multiclass classification 0.793579
8581 Tabular Playground Series - Dec 2021 multiclass classification tabular 0.793579
8240 Walmart Recruiting: Trip Type Classification multiclass classification tabular 0.793579
3362 Tabular Playground Series - Feb 2022 tabular multiclass classification 0.793579
5254 ICDM 2015: Drawbridge Cross-Device Connections multiclass classification tabular 0.793579
9633 Driver Telematics Analysis multiclass classification tabular 0.793579
7417 Homesite Quote Conversion binary classification tabular 0.688952
3646 Don't Overfit! II tabular binary classification 0.688952
6507 Categorical Feature Encoding Challenge tabular binary classification 0.688952
2460 Predict Student Performance from Game Play tabular binary classification 0.688952
ğŸ¤ The Hidden Web of Collaboration: Who Are You Really Teaming Up With?

Kaggle might feel like a solo sport at times, but competitions often bring out the best in collaboration. Some of the most creative solutions are born in feature teams, built through shared struggles of public LB swings and private LB plot twists.

ğŸ” Letâ€™s Visualize the Network
By connecting the dots between teammates, this graph maps out your collaboration history â€” showing not just who you've worked with, but how often. Edges get stronger the more youâ€™ve teamed up, and only the tightest connections survive the filter.

ğŸ’¡ What's Going On Under the Hood?
We:
Pull userâ€“team relationships from Meta Kaggle
Build an undirected graph where edges represent teammate collaborations
Filter out weak ties (you probably wouldn't recognize them anyway ğŸ‘€)
Zoom in on the most connected folks to keep it clean
ğŸ¯ Whether youâ€™re a lone wolf, a frequent co-pilot, or a social butterfly â€” this graph reveals how your journey on Kaggle intersects with others.
In [30]:
# Load datasets
users_df = pd.read_csv('/kaggle/input/meta-kaggle/Users.csv', usecols=['Id', 'UserName'])
team_df = pd.read_csv('/kaggle/input/meta-kaggle/Teams.csv', usecols=['Id', 'TeamName'])
members_df = pd.read_csv('/kaggle/input/meta-kaggle/TeamMemberships.csv')

# Merge to get team-user relationships
merged_df = members_df.merge(users_df, left_on='UserId', right_on='Id') \
                      .merge(team_df, left_on='TeamId', right_on='Id', suffixes=('_user', '_team'))

# Drop long usernames for visualization simplicity (optional)
merged_df = merged_df[merged_df['UserName'].str.len() < 20]

# Build the graph
G = nx.Graph()

# Add edges between teammates
teams = merged_df.groupby('TeamId')
for _, team in teams:
    users = team['UserName'].tolist()
    for i in range(len(users)):
        for j in range(i+1, len(users)):
            u, v = users[i], users[j]
            if G.has_edge(u, v):
                G[u][v]['weight'] += 1
            else:
                G.add_edge(u, v, weight=1)

# Remove weak edges for clarity
edges_to_remove = [(u, v) for u, v, d in G.edges(data=True) if d['weight'] < 2]
G.remove_edges_from(edges_to_remove)

# Optionally: focus on top connected users
if len(G) > 10:
    degree_dict = dict(G.degree())
    top_nodes = sorted(degree_dict, key=degree_dict.get, reverse=True)[:10]
    G = G.subgraph(top_nodes).copy()

# Draw graph
plt.figure(figsize=(15, 12))
pos = nx.spring_layout(G, seed=42)
node_sizes = [300 + 100 * G.degree(n) for n in G.nodes()]
nx.draw_networkx_nodes(G, pos, node_size=node_sizes, node_color='skyblue', alpha=0.8)
nx.draw_networkx_edges(G, pos, alpha=0.4, width=1)
nx.draw_networkx_labels(G, pos, font_size=8)
plt.title("Cleaned Feature Team Graph: Who Collaborates with Whom", fontsize=16)
plt.axis('off')
plt.tight_layout()
plt.show()
ğŸ And thatâ€™s a wrap!

I hope this project gave you a thoughtful (and slightly fun ğŸ˜„) lens into how we Kagglers show up on this platform.

Whether youâ€™re just getting started or youâ€™ve got medals aging like fine wine, the Meta Kaggle dataset tells a story â€” and I just tried to help it speak a little louder.

ğŸ’­ This wasnâ€™t just a dashboard...and to me this wasn't just a hackathon, this notebook goes beyond that
... a thankyou letter to the community and maybe a mirror reflecting what keeps us coming back to that â€œSubmitâ€ button.

ğŸ™Œ Thanks for scrolling, exploring, and being part of this wild ride.

See you on the Leaderboard â€” or maybe the Discussion tab! Stay curious. Stay caffeinated. Stay Kagglinâ€™ :)