Baseline Models
In Kaggle's Backpack Prediction Challenge, there is not much signal. The target appears to be mostly random. This is discussed in many discussion topics including here. In this notebook we create two baselines and try to extract a little signal.
This competition's dataset is synthetically created, so there will most likely be some artifact signal in the numerical column named Weight Capacity. This column is numerical, but synthetic generation may repeat values and give repeated values similar targets. Even if the original targets were random, having repeated targets in this competition's data will allow us to predict them. Thus there may be a little signal here.
We will submit baseline 1 (train mean) in version 1 of this notebook and we will submit baseline 2 (target encode weight capacity) in version 2 of this notebook. Afterward we will have two LB scores which we can use as baselines to compare against future models.
UPDATE: Baseline 1 achieves LB=39.16450. Now let's see what baseline 2 achieves...
Load Data
In [1]:
import pandas as pd, numpy as np

train = pd.read_csv("/kaggle/input/playground-series-s5e2/train.csv")
print("Train shape",train.shape)
train_extra = pd.read_csv("/kaggle/input/playground-series-s5e2/training_extra.csv")
print("Extra Train shape",train_extra.shape)
train = pd.concat([train,train_extra],axis=0,ignore_index=True)
print("Combined Train shape",train.shape)
train.head()
Train shape (300000, 11)
Extra Train shape (3694318, 11)
Combined Train shape (3994318, 11)
Out[1]:
id Brand Material Size Compartments Laptop Compartment Waterproof Style Color Weight Capacity (kg) Price
0 0 Jansport Leather Medium 7.0 Yes No Tote Black 11.611723 112.15875
1 1 Jansport Canvas Small 10.0 Yes Yes Messenger Green 27.078537 68.88056
2 2 Under Armour Leather Small 2.0 Yes No Messenger Red 16.643760 39.17320
3 3 Nike Nylon Small 8.0 Yes No Messenger Green 12.937220 80.60793
4 4 Adidas Canvas Medium 1.0 Yes Yes Messenger Green 17.749338 86.02312
Baseline 1 - Train Mean - CV 38.93, LB 39.16
In [2]:
train_mean = train.Price.mean()
train['pred'] = train_mean
s = np.sqrt(np.mean( (train.Price-train.pred)**2.0 ) )
print(f"Validation RMSE using Train Mean = {s}")
Validation RMSE using Train Mean = 38.93867923358143
In [3]:
sub = pd.read_csv("/kaggle/input/playground-series-s5e2/sample_submission.csv")
print('Submission shape', sub.shape)
sub['Price'] = train_mean
sub.to_csv("submission_mean.csv",index=False)
sub.head()
Submission shape (200000, 2)
Out[3]:
id Price
0 300000 81.362175
1 300001 81.362175
2 300002 81.362175
3 300003 81.362175
4 300004 81.362175
Baseline 2 - Target Encode Weight Capacity - CV 38.71
We will use RAPIDS Target Encoder to TE the numeric column weight capacity.
In [4]:
from cuml.preprocessing import TargetEncoder

TE = TargetEncoder(n_folds=25, smooth=20, split_method='random', stat='mean')
train['pred'] = TE.fit_transform(train['Weight Capacity (kg)'],train.Price)
s = np.sqrt(np.mean( (train.Price-train.pred)**2.0 ) )
print(f"Validation RSME using Target Encode Weight Capacity = {s}")
Validation RSME using Target Encode Weight Capacity = 38.711660965150045
In [5]:
test = pd.read_csv("/kaggle/input/playground-series-s5e2/test.csv")
sub['Price'] = TE.transform(test['Weight Capacity (kg)'])
sub.to_csv("submission_TE_weight_capacity.csv",index=False)
sub.head()
Out[5]:
id Price
0 300000 82.752365
1 300001 80.938726
2 300002 90.901021
3 300003 78.336685
4 300004 81.362175