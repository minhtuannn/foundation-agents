{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d093ecfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "https://www.kaggle.com/competitions/bigquery-ai-hackathon\n",
      "https://www.kaggle.com/competitions/cafa-6-protein-function-prediction\n",
      "https://www.kaggle.com/competitions/google-gemma-3n-hackathon\n",
      "https://www.kaggle.com/competitions/hull-tactical-market-prediction\n",
      "https://www.kaggle.com/competitions/jane-street-real-time-market-data-forecasting\n",
      "https://www.kaggle.com/competitions/meta-kaggle-hackathon\n",
      "https://www.kaggle.com/competitions/playground-series-s4e11\n",
      "https://www.kaggle.com/competitions/playground-series-s4e12\n",
      "https://www.kaggle.com/competitions/playground-series-s5e1\n",
      "https://www.kaggle.com/competitions/playground-series-s5e10\n",
      "https://www.kaggle.com/competitions/playground-series-s5e11\n",
      "https://www.kaggle.com/competitions/playground-series-s5e12\n",
      "https://www.kaggle.com/competitions/playground-series-s5e2\n",
      "https://www.kaggle.com/competitions/playground-series-s5e3\n",
      "https://www.kaggle.com/competitions/playground-series-s5e4\n",
      "https://www.kaggle.com/competitions/playground-series-s5e5\n",
      "https://www.kaggle.com/competitions/playground-series-s5e6\n",
      "https://www.kaggle.com/competitions/playground-series-s5e7\n",
      "https://www.kaggle.com/competitions/playground-series-s5e8\n",
      "https://www.kaggle.com/competitions/playground-series-s5e9\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from urllib.parse import urljoin\n",
    "from playwright.async_api import async_playwright\n",
    "\n",
    "URL = \"https://www.kaggle.com/competitions?tagIds=14101-Tabular\"\n",
    "COMP_RE = re.compile(r\"^/competitions/([^/?#]+)$\")\n",
    "\n",
    "async def fetch_competition_links(url: str, scroll_rounds: int = 25, pause_ms: int = 800):\n",
    "    async with async_playwright() as p:\n",
    "        browser = await p.chromium.launch(headless=True)\n",
    "        page = await browser.new_page()\n",
    "        await page.goto(url, wait_until=\"networkidle\")\n",
    "\n",
    "        for _ in range(scroll_rounds):\n",
    "            await page.evaluate(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "            await page.wait_for_timeout(pause_ms)\n",
    "\n",
    "        hrefs = await page.eval_on_selector_all(\n",
    "            \"a[href]\",\n",
    "            \"els => els.map(e => e.getAttribute('href'))\"\n",
    "        )\n",
    "        await browser.close()\n",
    "\n",
    "    slugs = set()\n",
    "    for href in hrefs:\n",
    "        if not href:\n",
    "            continue\n",
    "        href = href.strip()\n",
    "        m = COMP_RE.match(href)\n",
    "        if m:\n",
    "            slugs.add(m.group(1))\n",
    "\n",
    "    return [f\"https://www.kaggle.com/competitions/{s}\" for s in sorted(slugs)]\n",
    "\n",
    "links = await fetch_competition_links(URL, scroll_rounds=10)\n",
    "print(len(links))\n",
    "print(\"\\n\".join(links[:20]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d99b4d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling: https://www.kaggle.com/competitions/playground-series-s5e12/overview...\n",
      "  -> Warning: <main> tag not found for Overview, attempting fallback.\n",
      "--- Successfully extracted 4189 characters from Overview ---\n",
      "------------------------------\n",
      "Crawling: https://www.kaggle.com/competitions/playground-series-s5e12/data...\n",
      "  -> Warning: <main> tag not found for Data, attempting fallback.\n",
      "--- Successfully extracted 1909 characters from Data ---\n",
      "------------------------------\n",
      "Crawling: https://www.kaggle.com/competitions/playground-series-s5e12/rules...\n",
      "  -> Warning: <main> tag not found for Rules, attempting fallback.\n",
      "--- Successfully extracted 34000 characters from Rules ---\n",
      "------------------------------\n",
      "\n",
      "=== OVERVIEW CONTENT (Snippet) ===\n",
      "menu\n",
      "Create\n",
      "explore\n",
      "Home\n",
      "emoji_events\n",
      "Competitions\n",
      "table_chart\n",
      "Datasets\n",
      "tenancy\n",
      "Models\n",
      "leaderboard\n",
      "Benchmarks\n",
      "smart_toy\n",
      "Game Arena\n",
      "code\n",
      "Code\n",
      "comment\n",
      "Discussions\n",
      "school\n",
      "Learn\n",
      "expand_more\n",
      "More\n",
      "auto_awesome_motion\n",
      "View Active Events\n",
      "search\n",
      "Sign In\n",
      "Register\n",
      "Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\n",
      "Learn more\n",
      "OK, Got it.\n",
      "KAGGLE · PLAYGROUND PREDICTION COMPETITION · 5 DAYS TO GO\n",
      "Join Competition\n",
      "more_horiz\n",
      "Diabetes Prediction Challenge\n",
      "...\n",
      "[Content Truncated]\n",
      "\n",
      "=== DATA CONTENT (Snippet) ===\n",
      "menu\n",
      "Create\n",
      "explore\n",
      "Home\n",
      "emoji_events\n",
      "Competitions\n",
      "table_chart\n",
      "Datasets\n",
      "tenancy\n",
      "Models\n",
      "leaderboard\n",
      "Benchmarks\n",
      "smart_toy\n",
      "Game Arena\n",
      "code\n",
      "Code\n",
      "comment\n",
      "Discussions\n",
      "school\n",
      "Learn\n",
      "expand_more\n",
      "More\n",
      "auto_awesome_motion\n",
      "View Active Events\n",
      "search\n",
      "Sign In\n",
      "Register\n",
      "Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\n",
      "Learn more\n",
      "OK, Got it.\n",
      "KAGGLE · PLAYGROUND PREDICTION COMPETITION · 5 DAYS TO GO\n",
      "Join Competition\n",
      "more_horiz\n",
      "Diabetes Prediction Challenge\n",
      "...\n",
      "[Content Truncated]\n",
      "\n",
      "=== RULES CONTENT (Snippet) ===\n",
      "menu\n",
      "Create\n",
      "explore\n",
      "Home\n",
      "emoji_events\n",
      "Competitions\n",
      "table_chart\n",
      "Datasets\n",
      "tenancy\n",
      "Models\n",
      "leaderboard\n",
      "Benchmarks\n",
      "smart_toy\n",
      "Game Arena\n",
      "code\n",
      "Code\n",
      "comment\n",
      "Discussions\n",
      "school\n",
      "Learn\n",
      "expand_more\n",
      "More\n",
      "auto_awesome_motion\n",
      "View Active Events\n",
      "search\n",
      "Sign In\n",
      "Register\n",
      "Kaggle uses cookies from Google to deliver and enhance the quality of its services and to analyze traffic.\n",
      "Learn more\n",
      "OK, Got it.\n",
      "KAGGLE · PLAYGROUND PREDICTION COMPETITION · 5 DAYS TO GO\n",
      "Join Competition\n",
      "more_horiz\n",
      "Diabetes Prediction Challenge\n",
      "...\n",
      "[Content Truncated]\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Sets up the undetected_chromedriver.\"\"\"\n",
    "    options = uc.ChromeOptions()\n",
    "    \n",
    "    # Kaggle/Cloudflare is very sensitive to headless mode. \n",
    "    # It is highly recommended to run this WITHOUT headless first.\n",
    "    # If you must use headless, uncomment the line below:\n",
    "    # options.add_argument(\"--headless=new\") \n",
    "\n",
    "    # undetected_chromedriver handles the driver installation and patching automatically.\n",
    "    # We do not need webdriver_manager or Service objects here.\n",
    "    driver = uc.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "def get_tab_content(driver, base_url, tab_name):\n",
    "    \"\"\"Navigates to a specific tab and extracts the main text content.\"\"\"\n",
    "    tab_url = f\"{base_url}/{tab_name.lower()}\"\n",
    "    print(f\"Crawling: {tab_url}...\")\n",
    "    driver.get(tab_url)\n",
    "\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 30) # Increased wait time for Cloudflare checks\n",
    "        \n",
    "        # 1. Wait for body to ensure page load\n",
    "        wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "        \n",
    "        # 2. Check if we are stuck on the \"Checking your browser\" screen\n",
    "        title = driver.title\n",
    "        if \"reCAPTCHA\" in title or \"Checking your browser\" in title:\n",
    "            print(f\"  -> Detected Cloudflare challenge on {tab_name}. Waiting for redirect...\")\n",
    "            # Wait longer for the redirect to complete automatically\n",
    "            time.sleep(10) \n",
    "        \n",
    "        # 3. Try to find the main content\n",
    "        try:\n",
    "            # Kaggle content is usually in <main> or a specific div structure\n",
    "            main_element = wait.until(EC.presence_of_element_located((By.TAG_NAME, \"main\")))\n",
    "        except:\n",
    "            print(f\"  -> Warning: <main> tag not found for {tab_name}, attempting fallback.\")\n",
    "            # Fallback: sometimes content is in #site-content or just body if structure varies\n",
    "            main_element = driver.find_element(By.TAG_NAME, \"body\")\n",
    "        \n",
    "        # 4. Allow dynamic content to render\n",
    "        time.sleep(5)\n",
    "        \n",
    "        content = main_element.text\n",
    "        \n",
    "        # Validation: If content is still the \"Checking browser\" text, we failed.\n",
    "        if \"Checking your browser\" in content or len(content) < 200:\n",
    "            return f\"Error: Failed to bypass Cloudflare protection. Page content: {content[:100]}...\"\n",
    "\n",
    "        cleaned_content = \"\\n\".join([line for line in content.split('\\n') if line.strip()])\n",
    "        return cleaned_content\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting content for {tab_name}: {str(e)}\"\n",
    "\n",
    "base_url = \"https://www.kaggle.com/competitions/playground-series-s5e12\"\n",
    "tabs = [\"Overview\", \"Data\", \"Rules\"]\n",
    "\n",
    "driver = setup_driver()\n",
    "\n",
    "results = {}\n",
    "\n",
    "try:\n",
    "    for tab in tabs:\n",
    "        content = get_tab_content(driver, base_url, tab)\n",
    "        results[tab] = content\n",
    "        \n",
    "        if content.startswith(\"Error\"):\n",
    "                print(f\"--- Failed to extract {tab} ---\")\n",
    "                print(content)\n",
    "        else:\n",
    "                print(f\"--- Successfully extracted {len(content)} characters from {tab} ---\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "finally:\n",
    "    driver.quit()\n",
    "\n",
    "# Displaying a snippet of the results\n",
    "for tab, content in results.items():\n",
    "    print(f\"\\n=== {tab.upper()} CONTENT (Snippet) ===\")\n",
    "    print(content[:500] + \"...\\n[Content Truncated]\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f330382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling: https://www.kaggle.com/competitions/playground-series-s5e12/overview...\n",
      "  -> Warning: <main> tag not found for Overview, attempting fallback.\n",
      "--- Extracted 4189 characters from Overview ---\n",
      "------------------------------\n",
      "Crawling: https://www.kaggle.com/competitions/playground-series-s5e12/data...\n",
      "  -> Warning: <main> tag not found for Data, attempting fallback.\n",
      "--- Extracted 1909 characters from Data ---\n",
      "------------------------------\n",
      "Crawling: https://www.kaggle.com/competitions/playground-series-s5e12/rules...\n",
      "  -> Warning: <main> tag not found for Rules, attempting fallback.\n",
      "--- Extracted 34000 characters from Rules ---\n",
      "------------------------------\n",
      "\n",
      "Successfully saved content to: /Users/minhtuan/Documents/Documents/Work/Hanoi/crawler/playground-series-s5e12.txt\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Sets up the undetected_chromedriver.\"\"\"\n",
    "    options = uc.ChromeOptions()\n",
    "    # Running without headless mode is recommended to pass Cloudflare checks\n",
    "    driver = uc.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "def get_tab_content(driver, base_url, tab_name):\n",
    "    \"\"\"Navigates to a specific tab and extracts the main text content.\"\"\"\n",
    "    tab_url = f\"{base_url}/{tab_name.lower()}\"\n",
    "    print(f\"Crawling: {tab_url}...\")\n",
    "    driver.get(tab_url)\n",
    "\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 30)\n",
    "        \n",
    "        # 1. Wait for body to ensure page load\n",
    "        wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "        \n",
    "        # 2. Check for Cloudflare/reCAPTCHA title\n",
    "        if \"reCAPTCHA\" in driver.title or \"Checking your browser\" in driver.title:\n",
    "            print(f\"  -> Detected Cloudflare challenge on {tab_name}. Waiting for redirect...\")\n",
    "            time.sleep(10) \n",
    "        \n",
    "        # 3. Try to find the main content\n",
    "        try:\n",
    "            # Kaggle content is usually in <main>\n",
    "            main_element = wait.until(EC.presence_of_element_located((By.TAG_NAME, \"main\")))\n",
    "        except:\n",
    "            print(f\"  -> Warning: <main> tag not found for {tab_name}, attempting fallback.\")\n",
    "            main_element = driver.find_element(By.TAG_NAME, \"body\")\n",
    "        \n",
    "        # 4. Allow dynamic content to render\n",
    "        time.sleep(5)\n",
    "        \n",
    "        content = main_element.text\n",
    "        \n",
    "        # Basic validation\n",
    "        if \"Checking your browser\" in content or len(content) < 200:\n",
    "            return f\"Error: Failed to bypass Cloudflare protection or content empty.\"\n",
    "\n",
    "        # Clean up excessive newlines\n",
    "        cleaned_content = \"\\n\".join([line for line in content.split('\\n') if line.strip()])\n",
    "        return cleaned_content\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting content for {tab_name}: {str(e)}\"\n",
    "\n",
    "def get_filename_from_url(url):\n",
    "    \"\"\"Generates a filename from the URL slug.\"\"\"\n",
    "    if url.endswith('/'):\n",
    "        url = url[:-1]\n",
    "    # Extract the last part of the URL\n",
    "    slug = url.split('/')[-1]\n",
    "    return f\"{slug}.txt\"\n",
    "\n",
    "def main():\n",
    "    base_url = \"https://www.kaggle.com/competitions/playground-series-s5e12\"\n",
    "    tabs = [\"Overview\", \"Data\", \"Rules\"]\n",
    "    \n",
    "    driver = setup_driver()\n",
    "    results = {}\n",
    "    \n",
    "    try:\n",
    "        for tab in tabs:\n",
    "            content = get_tab_content(driver, base_url, tab)\n",
    "            results[tab] = content\n",
    "            print(f\"--- Extracted {len(content)} characters from {tab} ---\")\n",
    "            print(\"-\" * 30)\n",
    "            \n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    # Save to file\n",
    "    filename = get_filename_from_url(base_url)\n",
    "    \n",
    "    try:\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            for i, tab in enumerate(tabs):\n",
    "                content = results.get(tab, \"\")\n",
    "                \n",
    "                # Write Header\n",
    "                f.write(f\"{tab}\\n\")\n",
    "                # Write Content\n",
    "                f.write(f\"{content}\\n\")\n",
    "                \n",
    "                # Write Separator (except after the last item)\n",
    "                if i < len(tabs) - 1:\n",
    "                    f.write(\"-----\\n\")\n",
    "        \n",
    "        print(f\"\\nSuccessfully saved content to: {os.path.abspath(filename)}\")\n",
    "        \n",
    "    except IOError as e:\n",
    "        print(f\"Error writing to file: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e4c8ef3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling: https://www.kaggle.com/competitions/titanic/overview...\n",
      "  -> Warning: <main> tag not found for Overview, attempting fallback.\n",
      "--- Extracted 10110 characters from Overview ---\n",
      "------------------------------\n",
      "Crawling: https://www.kaggle.com/competitions/titanic/data...\n",
      "  -> Warning: <main> tag not found for Data, attempting fallback.\n",
      "--- Extracted 3143 characters from Data ---\n",
      "------------------------------\n",
      "Crawling: https://www.kaggle.com/competitions/titanic/rules...\n",
      "  -> Warning: <main> tag not found for Rules, attempting fallback.\n",
      "--- Extracted 24674 characters from Rules ---\n",
      "------------------------------\n",
      "\n",
      "Successfully saved content to: /Users/minhtuan/Documents/Documents/Work/Hanoi/crawler/titanic.txt\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "import undetected_chromedriver as uc\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "def setup_driver():\n",
    "    \"\"\"Sets up the undetected_chromedriver.\"\"\"\n",
    "    options = uc.ChromeOptions()\n",
    "    # Running with a visible window is recommended to pass Cloudflare checks\n",
    "    driver = uc.Chrome(options=options)\n",
    "    return driver\n",
    "\n",
    "def get_tab_content(driver, base_url, tab_name):\n",
    "    \"\"\"Navigates to a specific tab and extracts the main text content.\"\"\"\n",
    "    tab_url = f\"{base_url}/{tab_name.lower()}\"\n",
    "    print(f\"Crawling: {tab_url}...\")\n",
    "    driver.get(tab_url)\n",
    "\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 30)\n",
    "        wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "        \n",
    "        # Check for Cloudflare\n",
    "        if \"reCAPTCHA\" in driver.title or \"Checking your browser\" in driver.title:\n",
    "            print(f\"  -> Detected Cloudflare challenge on {tab_name}. Waiting...\")\n",
    "            time.sleep(10) \n",
    "        \n",
    "        try:\n",
    "            main_element = wait.until(EC.presence_of_element_located((By.TAG_NAME, \"main\")))\n",
    "        except:\n",
    "            print(f\"  -> Warning: <main> tag not found for {tab_name}, attempting fallback.\")\n",
    "            main_element = driver.find_element(By.TAG_NAME, \"body\")\n",
    "        \n",
    "        time.sleep(5) # Allow dynamic content to render\n",
    "        \n",
    "        content = main_element.text\n",
    "        cleaned_content = \"\\n\".join([line for line in content.split('\\n') if line.strip()])\n",
    "        return cleaned_content\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting content for {tab_name}: {str(e)}\"\n",
    "\n",
    "def get_code_content(driver, base_url):\n",
    "    \"\"\"\n",
    "    Navigates to the Code tab, sorts by 'Most Votes', and extracts content from top 10 notebooks.\n",
    "    \"\"\"\n",
    "    code_url = f\"{base_url}/code\"\n",
    "    print(f\"Crawling Code List: {code_url}...\")\n",
    "    driver.get(code_url)\n",
    "    \n",
    "    full_code_content = \"\"\n",
    "    \n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 30)\n",
    "        wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "        time.sleep(5) # Wait for initial load\n",
    "\n",
    "        # --- 1. Handle Sorting (Hotness -> Most Votes) ---\n",
    "        print(\"  -> Attempting to sort by 'Most Votes'...\")\n",
    "        try:\n",
    "            # Find the dropdown trigger (defaults to \"Hotness\")\n",
    "            # We use XPath to find the element containing the text \"Hotness\"\n",
    "            hotness_btn = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[contains(text(), 'Hotness')]\")))\n",
    "            hotness_btn.click()\n",
    "            time.sleep(1)\n",
    "            \n",
    "            # Find and click \"Most Votes\" in the dropdown menu\n",
    "            most_votes_btn = wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[contains(text(), 'Most Votes')]\")))\n",
    "            most_votes_btn.click()\n",
    "            \n",
    "            print(\"  -> Sort applied. Waiting for list to refresh...\")\n",
    "            time.sleep(5) \n",
    "        except Exception as e:\n",
    "            print(f\"  -> Warning: Could not interact with Sort dropdown (UI might have changed). Error: {e}\")\n",
    "\n",
    "        # --- 2. Extract Top 10 Notebook Links ---\n",
    "        links_found = []\n",
    "        elements = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "        \n",
    "        for elem in elements:\n",
    "            href = elem.get_attribute(\"href\")\n",
    "            # Filter for valid notebook links:\n",
    "            # 1. Must contain '/code/'\n",
    "            # 2. Must NOT be the main competition code tab (contains 'competitions')\n",
    "            # 3. Must NOT be the 'New Notebook' link\n",
    "            if href and \"/code/\" in href and \"competitions\" not in href and \"/new\" not in href:\n",
    "                if href not in links_found:\n",
    "                    links_found.append(href)\n",
    "        \n",
    "        top_10_links = links_found[:10]\n",
    "        print(f\"  -> Found {len(links_found)} notebooks. Processing top {len(top_10_links)}...\")\n",
    "\n",
    "        # --- 3. Crawl Each Notebook ---\n",
    "        for i, link in enumerate(top_10_links):\n",
    "            print(f\"    [{i+1}/10] Crawling notebook: {link}\")\n",
    "            try:\n",
    "                driver.get(link)\n",
    "                # Wait for the notebook content (main tag)\n",
    "                wait.until(EC.presence_of_element_located((By.TAG_NAME, \"main\")))\n",
    "                time.sleep(5) # Wait for cells/markdown to render\n",
    "                \n",
    "                title = driver.title.replace(\" | Kaggle\", \"\")\n",
    "                page_text = driver.find_element(By.TAG_NAME, \"main\").text\n",
    "                \n",
    "                # Clean up text\n",
    "                cleaned_text = \"\\n\".join([line for line in page_text.split('\\n') if line.strip()])\n",
    "                \n",
    "                # Append to result string\n",
    "                full_code_content += f\"Notebook {i+1}: {title}\\nURL: {link}\\n\"\n",
    "                full_code_content += \"-\" * 20 + \"\\n\"\n",
    "                full_code_content += cleaned_text + \"\\n\"\n",
    "                full_code_content += \"=\" * 40 + \"\\n\\n\"\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"    -> Error crawling notebook {link}: {e}\")\n",
    "                full_code_content += f\"Error crawling {link}: {e}\\n\\n\"\n",
    "                \n",
    "    except Exception as e:\n",
    "        return f\"Error in Code tab processing: {str(e)}\"\n",
    "        \n",
    "    return full_code_content\n",
    "\n",
    "def get_filename_from_url(url):\n",
    "    if url.endswith('/'):\n",
    "        url = url[:-1]\n",
    "    slug = url.split('/')[-1]\n",
    "    return f\"{slug}.txt\"\n",
    "\n",
    "def main():\n",
    "    base_url = \"https://www.kaggle.com/competitions/titanic\"\n",
    "    # Standard tabs\n",
    "    tabs = [\"Overview\", \"Data\", \"Rules\"]\n",
    "    \n",
    "    driver = setup_driver()\n",
    "    results = {}\n",
    "    \n",
    "    try:\n",
    "        # 1. Crawl Standard Tabs\n",
    "        for tab in tabs:\n",
    "            content = get_tab_content(driver, base_url, tab)\n",
    "            results[tab] = content\n",
    "            print(f\"--- Extracted {len(content)} characters from {tab} ---\")\n",
    "            print(\"-\" * 30)\n",
    "        \n",
    "        # # 2. Crawl Code Tab (Special Logic)\n",
    "        # code_content = get_code_content(driver, base_url)\n",
    "        # results[\"Code\"] = code_content\n",
    "        # print(f\"--- Extracted {len(code_content)} characters from Code (Top 10) ---\")\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n",
    "    # Save to file\n",
    "    filename = get_filename_from_url(base_url)\n",
    "    \n",
    "    try:\n",
    "        with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "            # Write Standard Tabs\n",
    "            for tab in tabs:\n",
    "                content = results.get(tab, \"\")\n",
    "                f.write(f\"{tab}\\n\")\n",
    "                f.write(f\"{content}\\n\")\n",
    "                f.write(\"-----\\n\")\n",
    "            \n",
    "            # Write Code Tab\n",
    "            f.write(\"Code (Top 10 Most Votes)\\n\")\n",
    "            f.write(results.get(\"Code\", \"\"))\n",
    "            f.write(\"-----\\n\")\n",
    "        \n",
    "        print(f\"\\nSuccessfully saved content to: {os.path.abspath(filename)}\")\n",
    "        \n",
    "    except IOError as e:\n",
    "        print(f\"Error writing to file: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e05100",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891ab119",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c037405f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Crawling: https://www.kaggle.com/competitions/titanic/data\n",
      "  -> Waiting for content to load...\n",
      "  -> Extracting main page context...\n",
      "  -> Looking for notebook iframe...\n",
      "  -> Warning: Could not extract iframe content: Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x00000001050c3dfc cxxbridge1$str$ptr + 3031016\n",
      "1   chromedriver                        0x00000001050bbcb8 cxxbridge1$str$ptr + 2997924\n",
      "2   chromedriver                        0x0000000104bb6b90 _RNvCsgXDX2mvAJAg_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 74192\n",
      "3   chromedriver                        0x0000000104bfdab4 _RNvCsgXDX2mvAJAg_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 364788\n",
      "4   chromedriver                        0x0000000104c3ea28 _RNvCsgXDX2mvAJAg_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 630888\n",
      "5   chromedriver                        0x0000000104bf222c _RNvCsgXDX2mvAJAg_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 317548\n",
      "6   chromedriver                        0x0000000105088194 cxxbridge1$str$ptr + 2786176\n",
      "7   chromedriver                        0x000000010508b900 cxxbridge1$str$ptr + 2800364\n",
      "8   chromedriver                        0x000000010506842c cxxbridge1$str$ptr + 2655768\n",
      "9   chromedriver                        0x000000010508c170 cxxbridge1$str$ptr + 2802524\n",
      "10  chromedriver                        0x0000000105058e10 cxxbridge1$str$ptr + 2592764\n",
      "11  chromedriver                        0x00000001050ab14c cxxbridge1$str$ptr + 2929464\n",
      "12  chromedriver                        0x00000001050ab2cc cxxbridge1$str$ptr + 2929848\n",
      "13  chromedriver                        0x00000001050bb910 cxxbridge1$str$ptr + 2996988\n",
      "14  libsystem_pthread.dylib             0x0000000185599c08 _pthread_start + 136\n",
      "15  libsystem_pthread.dylib             0x0000000185594ba8 thread_start + 8\n",
      "\n",
      "\n",
      "Successfully saved content to: s5e12-eda-xgb-competition-starter.txt\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "def get_notebook_content(url):\n",
    "    \"\"\"\n",
    "    Crawls the text content of a Kaggle notebook with robust error handling.\n",
    "    \"\"\"\n",
    "    options = Options()\n",
    "    # Add arguments to improve stability and prevent crashes\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--window-size=1920,1080')\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "    \n",
    "    # Attempt to initialize the driver\n",
    "    try:\n",
    "        # Using standard Selenium with webdriver_manager to avoid undetected_chromedriver crashes\n",
    "        driver_path = ChromeDriverManager().install()\n",
    "        if \"THIRD_PARTY_NOTICES\" in driver_path:\n",
    "            driver_dir = os.path.dirname(driver_path)\n",
    "            driver_path = os.path.join(driver_dir, \"chromedriver\")\n",
    "\n",
    "        if os.path.exists(driver_path):\n",
    "            os.chmod(driver_path, 0o755)\n",
    "\n",
    "        service = Service(driver_path)\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "    except Exception as e:\n",
    "        return f\"Error initializing driver: {str(e)}\"\n",
    "\n",
    "    try:\n",
    "        print(f\"Crawling: {url}\")\n",
    "        driver.set_page_load_timeout(60)\n",
    "        driver.get(url)\n",
    "\n",
    "        # Simple wait as requested\n",
    "        print(\"  -> Waiting for content to load...\")\n",
    "        time.sleep(5)\n",
    "\n",
    "        # 1. Get Main Page Content (Title, Votes, etc.)\n",
    "        print(\"  -> Extracting main page context...\")\n",
    "        main_content = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "\n",
    "        # 2. Switch to Notebook Iframe\n",
    "        print(\"  -> Looking for notebook iframe...\")\n",
    "        iframe_content = \"\"\n",
    "        try:\n",
    "            # Wait for iframe to be present\n",
    "            iframe = WebDriverWait(driver, 20).until(\n",
    "                EC.presence_of_element_located((By.ID, \"rendered-kernel-content\"))\n",
    "            )\n",
    "            print(\"  -> Found iframe. Switching context...\")\n",
    "            driver.switch_to.frame(iframe)\n",
    "            time.sleep(5) # Wait for iframe content to render\n",
    "            \n",
    "            # Scroll inside iframe\n",
    "            print(\"  -> Scrolling inside iframe...\")\n",
    "            last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            for _ in range(20):\n",
    "                driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "                time.sleep(1)\n",
    "                new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "                if new_height == last_height:\n",
    "                    break\n",
    "                last_height = new_height\n",
    "            \n",
    "            # Extract all text from iframe\n",
    "            print(\"  -> Extracting notebook content...\")\n",
    "            iframe_content = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "            \n",
    "            # Switch back\n",
    "            driver.switch_to.default_content()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"  -> Warning: Could not extract iframe content: {e}\")\n",
    "            \n",
    "        # Combine\n",
    "        content = f\"=== MAIN PAGE ===\\n{main_content}\\n\\n=== NOTEBOOK CONTENT ===\\n{iframe_content}\"\n",
    "        \n",
    "        # Basic validation\n",
    "        if not content or len(content) < 500:\n",
    "            return \"Error: Extracted content seems short. The notebook might not have loaded completely.\"\n",
    "\n",
    "        return content\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting notebook: {str(e)}\"\n",
    "    finally:\n",
    "        # Ensure driver is closed properly\n",
    "        try:\n",
    "            driver.quit()\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    target_url =  \"https://www.kaggle.com/code/masayakawamata/s5e12-eda-xgb-competition-starter\"\n",
    "    \n",
    "    notebook_text = get_notebook_content(target_url)\n",
    "    \n",
    "    filename = \"s5e12-eda-xgb-competition-starter.txt\"\n",
    "    with open(filename, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(notebook_text)\n",
    "    print(f\"\\nSuccessfully saved content to: {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f3b8624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Competition: https://www.kaggle.com/competitions/titanic ---\n",
      "  Crawling tab: https://www.kaggle.com/competitions/titanic/overview...\n",
      "    -> Warning: Could not extract content from https://www.kaggle.com/competitions/titanic/overview: Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x000000010104bdfc cxxbridge1$str$ptr + 3031016\n",
      "1   chromedriver                        0x0000000101043cb8 cxxbridge1$str$ptr + 2997924\n",
      "2   chromedriver                        0x0000000100b3eb90 _RNvCsgXDX2mvAJAg_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 74192\n",
      "3   chromedriver                        0x0000000100b85ab4 _RNvCsgXDX2mvAJAg_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 364788\n",
      "4   chromedriver                        0x0000000100bc6a28 _RNvCsgXDX2mvAJAg_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 630888\n",
      "5   chromedriver                        0x0000000100b7a22c _RNvCsgXDX2mvAJAg_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 317548\n",
      "6   chromedriver                        0x0000000101010194 cxxbridge1$str$ptr + 2786176\n",
      "7   chromedriver                        0x0000000101013900 cxxbridge1$str$ptr + 2800364\n",
      "8   chromedriver                        0x0000000100ff042c cxxbridge1$str$ptr + 2655768\n",
      "9   chromedriver                        0x0000000101014170 cxxbridge1$str$ptr + 2802524\n",
      "10  chromedriver                        0x0000000100fe0e10 cxxbridge1$str$ptr + 2592764\n",
      "11  chromedriver                        0x000000010103314c cxxbridge1$str$ptr + 2929464\n",
      "12  chromedriver                        0x00000001010332cc cxxbridge1$str$ptr + 2929848\n",
      "13  chromedriver                        0x0000000101043910 cxxbridge1$str$ptr + 2996988\n",
      "14  libsystem_pthread.dylib             0x0000000185599c08 _pthread_start + 136\n",
      "15  libsystem_pthread.dylib             0x0000000185594ba8 thread_start + 8\n",
      "\n",
      "  Crawling tab: https://www.kaggle.com/competitions/titanic/data...\n",
      "    -> Warning: Could not extract content from https://www.kaggle.com/competitions/titanic/data: Message: \n",
      "Stacktrace:\n",
      "0   chromedriver                        0x000000010104bdfc cxxbridge1$str$ptr + 3031016\n",
      "1   chromedriver                        0x0000000101043cb8 cxxbridge1$str$ptr + 2997924\n",
      "2   chromedriver                        0x0000000100b3eb90 _RNvCsgXDX2mvAJAg_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 74192\n",
      "3   chromedriver                        0x0000000100b85ab4 _RNvCsgXDX2mvAJAg_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 364788\n",
      "4   chromedriver                        0x0000000100bc6a28 _RNvCsgXDX2mvAJAg_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 630888\n",
      "5   chromedriver                        0x0000000100b7a22c _RNvCsgXDX2mvAJAg_7___rustc35___rust_no_alloc_shim_is_unstable_v2 + 317548\n",
      "6   chromedriver                        0x0000000101010194 cxxbridge1$str$ptr + 2786176\n",
      "7   chromedriver                        0x0000000101013900 cxxbridge1$str$ptr + 2800364\n",
      "8   chromedriver                        0x0000000100ff042c cxxbridge1$str$ptr + 2655768\n",
      "9   chromedriver                        0x0000000101014170 cxxbridge1$str$ptr + 2802524\n",
      "10  chromedriver                        0x0000000100fe0e10 cxxbridge1$str$ptr + 2592764\n",
      "11  chromedriver                        0x000000010103314c cxxbridge1$str$ptr + 2929464\n",
      "12  chromedriver                        0x00000001010332cc cxxbridge1$str$ptr + 2929848\n",
      "13  chromedriver                        0x0000000101043910 cxxbridge1$str$ptr + 2996988\n",
      "14  libsystem_pthread.dylib             0x0000000185599c08 _pthread_start + 136\n",
      "15  libsystem_pthread.dylib             0x0000000185594ba8 thread_start + 8\n",
      "\n",
      "  Crawling tab: https://www.kaggle.com/competitions/titanic/rules...\n",
      "  Getting notebook links from: https://www.kaggle.com/competitions/titanic/code...\n",
      "    -> Sorting by 'Most Votes'...\n",
      "    -> Found 20 links, taking top 10.\n",
      "\n",
      "Saved main competition data to: titanic/titanic.txt\n",
      "\n",
      "--- Crawling 10 notebooks for titanic ---\n",
      "    Crawling notebook: https://www.kaggle.com/code/alexisbcook/titanic-tutorial\n",
      "  -> Waiting for content to load...\n",
      "  -> Extracting main page context...\n",
      "  -> Looking for notebook iframe...\n",
      "  -> Found iframe. Switching context...\n",
      "  -> Scrolling inside iframe...\n",
      "  -> Extracting notebook content...\n",
      "      -> Saved to titanic/notebooks/titanic-tutorial.txt\n",
      "    Crawling notebook: https://www.kaggle.com/code/gusthema/titanic-competition-w-tensorflow-decision-forests\n",
      "  -> Waiting for content to load...\n",
      "  -> Extracting main page context...\n",
      "  -> Looking for notebook iframe...\n",
      "  -> Found iframe. Switching context...\n",
      "  -> Scrolling inside iframe...\n",
      "  -> Extracting notebook content...\n",
      "      -> Saved to titanic/notebooks/titanic-competition-w-tensorflow-decision-forests.txt\n",
      "    Crawling notebook: https://www.kaggle.com/code/alexisbcook/exercise-arithmetic-and-variables\n",
      "  -> Waiting for content to load...\n",
      "  -> Extracting main page context...\n",
      "  -> Looking for notebook iframe...\n",
      "  -> Found iframe. Switching context...\n",
      "  -> Scrolling inside iframe...\n",
      "  -> Extracting notebook content...\n",
      "      -> Saved to titanic/notebooks/exercise-arithmetic-and-variables.txt\n",
      "    Crawling notebook: https://www.kaggle.com/code/startupsci/titanic-data-science-solutions\n",
      "  -> Waiting for content to load...\n",
      "  -> Extracting main page context...\n",
      "  -> Looking for notebook iframe...\n",
      "  -> Found iframe. Switching context...\n",
      "  -> Scrolling inside iframe...\n",
      "  -> Extracting notebook content...\n",
      "      -> Saved to titanic/notebooks/titanic-data-science-solutions.txt\n",
      "    Crawling notebook: https://www.kaggle.com/code/arthurtok/introduction-to-ensembling-stacking-in-python\n",
      "  -> Waiting for content to load...\n",
      "  -> Extracting main page context...\n",
      "  -> Looking for notebook iframe...\n",
      "  -> Found iframe. Switching context...\n",
      "  -> Scrolling inside iframe...\n",
      "  -> Extracting notebook content...\n",
      "      -> Saved to titanic/notebooks/introduction-to-ensembling-stacking-in-python.txt\n",
      "    Crawling notebook: https://www.kaggle.com/code/ldfreeman3/a-data-science-framework-to-achieve-99-accuracy\n",
      "  -> Waiting for content to load...\n",
      "  -> Extracting main page context...\n",
      "  -> Looking for notebook iframe...\n",
      "  -> Found iframe. Switching context...\n",
      "  -> Scrolling inside iframe...\n",
      "  -> Extracting notebook content...\n",
      "      -> Saved to titanic/notebooks/a-data-science-framework-to-achieve-99-accuracy.txt\n",
      "    Crawling notebook: https://www.kaggle.com/code/mrisdal/exploring-survival-on-the-titanic\n",
      "  -> Waiting for content to load...\n",
      "  -> Extracting main page context...\n",
      "  -> Looking for notebook iframe...\n",
      "  -> Found iframe. Switching context...\n",
      "  -> Scrolling inside iframe...\n",
      "  -> Extracting notebook content...\n",
      "      -> Saved to titanic/notebooks/exploring-survival-on-the-titanic.txt\n",
      "    Crawling notebook: https://www.kaggle.com/code/omarelgabry/a-journey-through-titanic\n",
      "  -> Waiting for content to load...\n",
      "  -> Extracting main page context...\n",
      "  -> Looking for notebook iframe...\n",
      "  -> Found iframe. Switching context...\n",
      "  -> Scrolling inside iframe...\n",
      "  -> Extracting notebook content...\n",
      "      -> Saved to titanic/notebooks/a-journey-through-titanic.txt\n",
      "    Crawling notebook: https://www.kaggle.com/code/helgejo/an-interactive-data-science-tutorial\n",
      "  -> Waiting for content to load...\n",
      "  -> Extracting main page context...\n",
      "  -> Looking for notebook iframe...\n",
      "  -> Found iframe. Switching context...\n",
      "  -> Scrolling inside iframe...\n",
      "  -> Extracting notebook content...\n",
      "      -> Saved to titanic/notebooks/an-interactive-data-science-tutorial.txt\n",
      "    Crawling notebook: https://www.kaggle.com/code/ash316/eda-to-prediction-dietanic\n",
      "  -> Waiting for content to load...\n",
      "  -> Extracting main page context...\n",
      "  -> Looking for notebook iframe...\n",
      "  -> Found iframe. Switching context...\n",
      "  -> Scrolling inside iframe...\n",
      "  -> Extracting notebook content...\n",
      "      -> Saved to titanic/notebooks/eda-to-prediction-dietanic.txt\n",
      "\n",
      "Workflow finished. Closing driver.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import os\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "# Add all the competition homepages you want to crawl here\n",
    "URLS_TO_CRAWL = [\n",
    "    \"https://www.kaggle.com/competitions/titanic\"\n",
    "]\n",
    "\n",
    "# URLS_TO_CRAWL = links \n",
    "\n",
    "# --- DRIVER SETUP ---\n",
    "def setup_driver():\n",
    "    \"\"\"Sets up a stable Chrome driver with stealth options.\"\"\"\n",
    "    options = Options()\n",
    "    options.add_argument('--no-sandbox')\n",
    "    options.add_argument('--disable-dev-shm-usage')\n",
    "    options.add_argument('--disable-gpu')\n",
    "    options.add_argument('--window-size=1920,1080')\n",
    "    options.add_argument(\"user-agent=Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "    \n",
    "    # Use a persistent profile to avoid CAPTCHA on subsequent runs\n",
    "    profile_path = os.path.join(os.getcwd(), \"selenium_profile\")\n",
    "    options.add_argument(f\"--user-data-dir={profile_path}\")\n",
    "\n",
    "    try:\n",
    "        driver_path = ChromeDriverManager().install()\n",
    "        if \"THIRD_PARTY_NOTICES\" in driver_path:\n",
    "            driver_dir = os.path.dirname(driver_path)\n",
    "            driver_path = os.path.join(driver_dir, \"chromedriver\")\n",
    "        if os.path.exists(driver_path):\n",
    "            os.chmod(driver_path, 0o755)\n",
    "        service = Service(driver_path)\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "        return driver\n",
    "    except Exception as e:\n",
    "        print(f\"Fatal Error: Could not initialize driver: {e}\")\n",
    "        return None\n",
    "\n",
    "# --- CRAWLING FUNCTIONS ---\n",
    "def get_tab_content(driver, url):\n",
    "    \"\"\"Navigates to a specific tab URL and extracts the main text content.\"\"\"\n",
    "    print(f\"  Crawling tab: {url}...\")\n",
    "    driver.get(url)\n",
    "    try:\n",
    "        # Wait for the main content area to load\n",
    "        WebDriverWait(driver, 20).until(EC.presence_of_element_located((By.ID, \"site-content\")))\n",
    "        time.sleep(3)\n",
    "        return driver.find_element(By.ID, \"site-content\").text\n",
    "    except Exception as e:\n",
    "        print(f\"    -> Warning: Could not extract content from {url}: {e}\")\n",
    "        return f\"Error extracting content from {url}.\"\n",
    "\n",
    "def get_top_notebook_links(driver, base_url):\n",
    "    \"\"\"Navigates to the Code tab, sorts by 'Most Votes', and returns top 10 links.\"\"\"\n",
    "    code_url = f\"{base_url}/code\"\n",
    "    print(f\"  Getting notebook links from: {code_url}...\")\n",
    "    driver.get(code_url)\n",
    "    \n",
    "    links = []\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 30)\n",
    "        wait.until(EC.presence_of_element_located((By.TAG_NAME, \"body\")))\n",
    "        time.sleep(5)\n",
    "\n",
    "        # Sort by 'Most Votes'\n",
    "        print(\"    -> Sorting by 'Most Votes'...\")\n",
    "        wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[contains(text(), 'Hotness')]\"))).click()\n",
    "        time.sleep(1)\n",
    "        wait.until(EC.element_to_be_clickable((By.XPATH, \"//*[contains(text(), 'Most Votes')]\"))).click()\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Extract links\n",
    "        elements = driver.find_elements(By.TAG_NAME, \"a\")\n",
    "        for elem in elements:\n",
    "            href = elem.get_attribute(\"href\")\n",
    "            if href and \"/code/\" in href and \"competitions\" not in href and \"/new\" not in href:\n",
    "                # FIX: Remove /comments suffix to get the notebook URL\n",
    "                if href.endswith(\"/comments\"):\n",
    "                    href = href.replace(\"/comments\", \"\")              \n",
    "                if href not in links:\n",
    "                    links.append(href)\n",
    "        \n",
    "        print(f\"    -> Found {len(links)} links, taking top 10.\")\n",
    "        return links[:10]\n",
    "    except Exception as e:\n",
    "        print(f\"    -> Error getting notebook links: {e}\")\n",
    "        return []\n",
    "\n",
    "def get_single_notebook_content(driver, url):\n",
    "    \"\"\"Crawls the full content of a single notebook page, handling the iframe.\"\"\"\n",
    "    print(f\"    Crawling notebook: {url}\")\n",
    "    driver.set_page_load_timeout(60)\n",
    "    driver.get(url)\n",
    "\n",
    "    # Simple wait as requested\n",
    "    print(\"  -> Waiting for content to load...\")\n",
    "    time.sleep(5)\n",
    "\n",
    "    # 1. Get Main Page Content (Title, Votes, etc.)\n",
    "    print(\"  -> Extracting main page context...\")\n",
    "    main_content = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "\n",
    "    # 2. Switch to Notebook Iframe\n",
    "    print(\"  -> Looking for notebook iframe...\")\n",
    "    iframe_content = \"\"\n",
    "    try:\n",
    "        # Wait for iframe to be present\n",
    "        iframe = WebDriverWait(driver, 20).until(\n",
    "            EC.presence_of_element_located((By.ID, \"rendered-kernel-content\"))\n",
    "        )\n",
    "        print(\"  -> Found iframe. Switching context...\")\n",
    "        driver.switch_to.frame(iframe)\n",
    "        time.sleep(5) # Wait for iframe content to render\n",
    "        \n",
    "        # Scroll inside iframe\n",
    "        print(\"  -> Scrolling inside iframe...\")\n",
    "        last_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "        for _ in range(20):\n",
    "            driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "            time.sleep(1)\n",
    "            new_height = driver.execute_script(\"return document.body.scrollHeight\")\n",
    "            if new_height == last_height:\n",
    "                break\n",
    "            last_height = new_height\n",
    "        \n",
    "        # Extract all text from iframe\n",
    "        print(\"  -> Extracting notebook content...\")\n",
    "        iframe_content = driver.find_element(By.TAG_NAME, \"body\").text\n",
    "        \n",
    "        # Switch back\n",
    "        driver.switch_to.default_content()\n",
    "            \n",
    "    except Exception as e:\n",
    "        iframe_content = f\"Error extracting notebook content from iframe: {e}\"\n",
    "    finally:\n",
    "        # Always switch back to the main page context\n",
    "        driver.switch_to.default_content()\n",
    "    \n",
    "    # Combine\n",
    "    content = f\"=== MAIN PAGE ===\\n{main_content}\\n\\n=== NOTEBOOK CONTENT ===\\n{iframe_content}\"\n",
    "    \n",
    "    # Basic validation\n",
    "    if not content or len(content) < 500:\n",
    "        return \"Error: Extracted content seems short. The notebook might not have loaded completely.\"\n",
    "\n",
    "    return iframe_content\n",
    "\n",
    "# --- HELPER FUNCTIONS ---\n",
    "def slugify(url, option):\n",
    "    \"\"\"Creates a clean filename or directory name from a URL.\"\"\"\n",
    "    if url.endswith('/'):\n",
    "        url = url[:-1]\n",
    "    return url.split('/')[option].replace('?','-').replace('=','-')\n",
    "\n",
    "# --- MAIN WORKFLOW ---\n",
    "def main():\n",
    "    \"\"\"Main workflow to crawl competitions and their notebooks.\"\"\"\n",
    "    driver = setup_driver()\n",
    "    if not driver:\n",
    "        return\n",
    "\n",
    "    try:\n",
    "        for base_url in URLS_TO_CRAWL:\n",
    "            print(f\"\\n--- Starting Competition: {base_url} ---\")\n",
    "            \n",
    "            # 1. Setup directories\n",
    "            comp_slug = slugify(base_url, -1)\n",
    "            os.makedirs(comp_slug, exist_ok=True)\n",
    "            notebooks_dir = os.path.join(comp_slug, \"notebooks\")\n",
    "            os.makedirs(notebooks_dir, exist_ok=True)\n",
    "            \n",
    "            # 2. Crawl main competition tabs\n",
    "            results = {}\n",
    "            tabs_to_crawl = [\"Overview\", \"Data\", \"Rules\"]\n",
    "            for tab in tabs_to_crawl:\n",
    "                results[tab] = get_tab_content(driver, f\"{base_url}/{tab.lower()}\")\n",
    "            \n",
    "            # 3. Get notebook links from the \"Code\" tab\n",
    "            top_links = get_top_notebook_links(driver, base_url)\n",
    "            results[\"Code\"] = \"Top 10 Notebook Links:\\n\" + \"\\n\".join(top_links)\n",
    "            \n",
    "            # 4. Save main competition file\n",
    "            main_filename = os.path.join(comp_slug, f\"{comp_slug}.txt\")\n",
    "            with open(main_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                for tab, content in results.items():\n",
    "                    f.write(f\"=== {tab.upper()} ===\\n\")\n",
    "                    f.write(content + \"\\n\\n\")\n",
    "            print(f\"\\nSaved main competition data to: {main_filename}\")\n",
    "\n",
    "            # 5. Crawl each notebook from the links found\n",
    "            print(f\"\\n--- Crawling {len(top_links)} notebooks for {comp_slug} ---\")\n",
    "            for link in top_links:\n",
    "                notebook_slug = slugify(link, -1)\n",
    "                notebook_filename = os.path.join(notebooks_dir, f\"{notebook_slug}.txt\")\n",
    "                \n",
    "                # Get content\n",
    "                notebook_content = get_single_notebook_content(driver, link)\n",
    "                \n",
    "                # Save content\n",
    "                with open(notebook_filename, \"w\", encoding=\"utf-8\") as f:\n",
    "                    f.write(notebook_content)\n",
    "                print(f\"      -> Saved to {notebook_filename}\")\n",
    "\n",
    "    finally:\n",
    "        print(\"\\nWorkflow finished. Closing driver.\")\n",
    "        driver.quit()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29dba459",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hanoi",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
